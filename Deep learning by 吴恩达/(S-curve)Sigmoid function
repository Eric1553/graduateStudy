A logistic function or logistic curve is a common S-shaped curve (sigmoid curve) with equation
逻辑斯蒂函数（逻辑斯蒂回归）是一种s型曲线，其通常形式为f(x) = L/(1 + exp(-k(x - x0))     定义域为整个实数域R
  其中：
    L为函数的最大值（x->正无穷的极限）
    x0为取得中点的位置
    k为曲线增长速率

sigmoid 函数是神经网络中的常见的激活函数，其标准形式为 f(x) = 1/(1 + exp(-x))
  具有以下的数学性质：
    derivative：f'(x) = f(x)(1-f(x))
    integral:ln(1 + exp(x))
    symmetry:(0,1/2)
sigmoid函数可以从双曲正切函数变化过来（双曲正切函数tanh = sinh / cosh）  tanh = (exp(-x) - exp(x)) / (exp(-x) + exp(x))
  sigmoid = 1/2 + （1/2）* tanh(x/2)
  
###
为何在机器学习的分类或回归问题中选择逻辑斯蒂函数呢？

 对于我们的分类问题，即已知许多特征x，希望通过这些特征预测出label，就是类别的标签，对于二分类问题，标签只有两个，这里记做0和1（有的记做+1和-1）。
对于x，我们希望用一个模型，最终综合起所有的特征x，然后得到一个待判决的数值，要想判断具体属于哪一类，需要设定一个阈值，大于这个阈值给一个类别，小于则给另一个类别，
就像最基本的高维空间用超平面分割两类一样。这样，我们实际上还需要一个带有阈值的阶跃函数，小于某个值函数值为0，大于为1。

如果这个待判决数值由特征的线性组合产生，那么最终的判别结果就是：  label^=stepfunc(wTx+b)

stepfun就是阶跃函数，由于有bias，所以阈值直接给0就可以。因为bias可以选取。但是阶跃函数不可导，由于我们要学习参数w和b势必要求导，因此我们用logistic来代替阶跃，用来作为一个阈值判别器。

 logistic有诸多好处，首先，它是光滑可导的，为学习提供了方便；另外，它是有界的，界就是0到1。
也就是说，它可以把-inf到+inf的线性函数的输出压缩到0～1，而且在x=0处，函数值为0.5，刚好可以作为阈值；0~1正好也是概率的范围，因此可以用它模拟概率。
因此选择它作为机器学习的激活函数，或者说模型函数。

