2.1 进行误差分析（Carrying out error analysis）
如果你希望让学习算法能够胜任人类能做的任务，但你的学习算法还没有达到人类的表现，那么人工检查一下你的算法犯的错误也许可以让你了解接下来应该做什么。这个过程称为错误分析。

假设你正在调试猫分类器，然后你取得了 90%准确率，相当于 10%错误，，在你的开发集上做到这样，这离你希望的目标还有很远。也许你的队员看了一下算法分类出错的例子，
注意到算法将一些狗分类为猫，你看看这两只狗，它们看起来是有点像猫，至少乍一看是。所以也许你的队友给你一个建议，如何针对狗的图片优化算法。试想一下，你可以针对狗，
收集更多的狗图，或者设计一些只处理狗的算法功能之类的，为了让你的猫分类器在狗图上做的更好，让算法不再将狗分类成猫。所以问题在于，你是不是应该去开始做一个项目专门
处理狗？这项目可能需要花费几个月的时间才能让算法在狗图片上犯更少的错误，这样做值得吗？或者与其花几个月做这个项目，有可能最后发现这样一点用都没有。这里有个错误分
析流程，可以让你很快知道这个方向是否值得努力。

首先，收集一下，比如说 100 个错误标记的开发集样本，然后手动检查，一次只看一个，看看你的开发集里有多少错误标记的样本是狗。现在，假设事实上，你的 100 个错误标记样本中只有 5%是狗，
就是说在 100 个错误标记的开发集样本中，有 5个是狗。这意味着 100 个样本，在典型的 100 个出错样本中，即使你完全解决了狗的问题，你也只能修正这 100 个错误中的 5 个。
或者换句话说，如果只有 5%的错误是狗图片，那么如果你在狗的问题上花了很多时间，那么你最多只能希望你的错误率从 10%下降到 9.5%，对吧？错误率相对下降了 5%
（总体下降了 0.5%，100 的错误样本，错误率为 10%，则样本为 1000），那就是 10%下降到 9.5%。你就可以确定这样花时间不好，或者也许应该花时间，但至少这个分析给出了一个上限。
如果你继续处理狗的问题，能够改善算法性能的上限，对吧？在机器学习中，有时我们称之为性能上限，就意味着，最好能到哪里，完全解决狗的问题可以对你有多少帮助。
（简单的说就是某个错误如果在总的错误类型中所占的比例很少，即使对其进行优化也不会产生什么优化效果，因此可以指导我们总的优化方向）

假设发生了另一件事，假设我们观察一下这 100 个错误标记的开发集样本，你发现实际有 50 张图都是狗，所以有 50%都是狗的照片，现在花时间去解决狗的问题可能效
果就很好。这种情况下，如果你真的解决了狗的问题，那么你的错误率可能就从 10%下降到5%了。然后你可能觉得让错误率减半的方向值得一试，可以集中精力减少错误标记的狗图
的问题。（如果某种错误类型在总的错误中占据许多的比重，那我们有必要对这种类型的问题进行解决从而降低偏差）

总结：人工对错误的样本进行分析不是一件没有意义的工作，相反很有可能给未来的优化指明方向。

我们要描述一下如何使用错误分析来评估某个想法，这个样本里狗的问题是否值得解决。有时你在做错误分析时，也可以同时并行评估几个想法，比如，你有几个
改善猫检测器的想法，也许你可以改善针对狗图的性能，或者有时候要注意，那些猫科动物，如狮子，豹，猎豹等等，它们经常被分类成小猫或者家猫，所以你也许可以想办法解决这个
错误。或者也许你发现有些图像是模糊的，如果你能设计出一些系统，能够更好地处理模糊图像。也许你有些想法，知道大概怎么处理这些问题，要进行错误分析来评估这三个想法。  

我会做的是建立这样一个表格，我通常用电子表格来做，但普通文本文件也可以。在最左边，人工过一遍你想分析的图像集，所以图像可能是从 1 到 100，如果你观察 100 张图的
话。电子表格的一列就对应你要评估的想法，所以狗的问题，猫科动物的问题，模糊图像的问题，我通常也在电子表格中留下空位来写评论。所以记住，在错误分析过程中，你就看看
算法识别错误的开发集样本，如果你发现第一张识别错误的图片是狗图，那么我就在那里打个勾，为了帮我自己记住这些图片，有时我会在评论里注释，也许这是一张比特犬的图。如
果第二张照片很模糊，也记一下。如果第三张是在下雨天动物园里的狮子，被识别成猫了，这是大型猫科动物，还有图片模糊，在评论部分写动物园下雨天，是雨天让图像模糊的之类
的。最后，这组图像过了一遍之后，我可以统计这些算法(错误)的百分比，或者这里每个错误类型的百分比，有多少是狗，大猫或模糊这些错误类型。所以也许你检查的图像中 8%是
狗，可能 43%属于大猫，61%属于模糊。这意味着扫过每一列，并统计那一列有多少百分比图像打了勾。（以表格的形式对错误进行统计从而找到具体的优化方向）

在这个步骤做到一半时，有时你可能会发现其他错误类型，比如说你可能发现有Instagram 滤镜，那些花哨的图像滤镜，干扰了你的分类器。在这种情况下，实际上可以在
错误分析途中，增加这样一列，比如多色滤镜 Instagram 滤镜和 Snapchat 滤镜，然后再过一遍，也统计一下那些问题，并确定这个新的错误类型占了多少百分比，这个分析步骤的结
果可以给出一个估计，是否值得去处理每个不同的错误类型。

例如，在这个样本中，有很多错误来自模糊图片，也有很多错误类型是大猫图片。所以这个分析的结果不是说你一定要处理模糊图片，这个分析没有给你一个严格的数学公式，告
诉你应该做什么，但它能让你对应该选择那些手段有个概念。它也告诉你，比如说不管你对狗图片或者 Instagram 图片处理得有多好，在这些例子中，你最多只能取得 8%或者 12%的
性能提升。而在大猫图片这一类型，你可以做得更好。或者模糊图像，这些类型有改进的潜力。这些类型里，性能提高的上限空间要大得多。所以取决于你有多少改善性能的想法，比
如改善大猫图片或者模糊图片的表现。也许你可以选择其中两个，或者你的团队成员足够多，也许你把团队可以分成两个团队，其中一个想办法改善大猫的识别，另一个团队想办法改善
模糊图片的识别。但这个快速统计的步骤，你可以经常做，最多需要几小时，就可以真正帮你选出高优先级任务，并了解每种手段对性能有多大提升空间。（挑选出高优先级的任务优先处理）

所以总结一下，进行错误分析，你应该找一组错误样本，可能在你的开发集里或者测试集里，观察错误标记的样本，看看假阳性（false positives）和假阴性（false negatives），统
计属于不同错误类型的错误数量。在这个过程中，你可能会得到启发，归纳出新的错误类型，就像我们看到的那样。如果你过了一遍错误样本，然后说，天，有这么多 Instagram 滤镜或
Snapchat 滤镜，这些滤镜干扰了我的分类器，你就可以在途中新建一个错误类型。总之，通过统计不同错误标记类型占总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你
构思新优化方向的灵感。在做错误分析的时候，有时你会注意到开发集里有些样本被错误标记了，这时应该怎么做呢？

2.2 清除标注错误的数据（Cleaning up Incorrectly labeled data）
我们看看在猫分类问题中，图片是猫，𝑦 = 1；不是猫，𝑦 = 0。所以假设你看了一些数据样本，发现这（倒数第二张图片）其实不是猫，所以这是标记错误的样本。我用了这个词，
“标记错误的样本”来表示你的学习算法输出了错误的 𝑦 值。但我要说的是，对于标记错误的样本，参考你的数据集，在训练集或者测试集 𝑦 的标签，人类给这部分数据加 的标签，实际上是错的，
这实际上是一只狗，所以 𝑦 其实应该是 0，也许做标记的那人疏忽了。如果你发现你的数据有一些标记错误的样本，你该怎么办？

首先，我们来考虑训练集，事实证明，深度学习算法对于训练集中的随机错误是相当健壮的（robust）。只要你的标记出错的样本，只要这些错误样本离随机错误不太远，有时可
能做标记的人没有注意或者不小心，按错键了，如果错误足够随机，那么放着这些错误不管可能也没问题，而不要花太多时间修复它们。(算法的鲁棒性可以降低算法对错误标记的反应)

当然你浏览一下训练集，检查一下这些标签，并修正它们也没什么害处。有时候修正这些错误是有价值的，有时候放着不管也可以，只要总数据集总足够大，实际错误率可能不会
太高。我见过一大批机器学习算法训练的时候，明知训练集里有𝑥个错误标签，但最后训练出来也没问题。
深度学习算法对随机误差很健壮，但对系统性的错误就没那么健壮了。所以比如说，如果做标记的人一直把白色的狗标记成猫，那就成问题了。因为你的分类器学习之后，会把所有白色的狗都分类为猫。
但随机错误或近似随机错误，对于大多数深度学习算法来说不成问题。（算法对于随机误差具有鲁棒性但是对于系统误差就无法忽视，因为系统误差会改变算法本身的分类标准从而产生不可逆转的分类错误）

方法：使用表格的方式来对训练集和验证集中标签预测结果不一致的样本进行分析，研究是标签本身的标记错误还是分类器出错。
结论：是否应该对这些错误的标签进行修正？
如果这些标记错误严重影响了你在开发集上评估算法的能力，那么就应该去花时间修正错误的标签。但是，如果它们没有严重影响到你用开发集评估成本偏差的能力，那么可能就不应该花宝贵的时间去处理。
（如果错误的标签对结果影响很大，即错误的内容在总的错误原因中的占比很高，那么就应该花时间去处理）











































