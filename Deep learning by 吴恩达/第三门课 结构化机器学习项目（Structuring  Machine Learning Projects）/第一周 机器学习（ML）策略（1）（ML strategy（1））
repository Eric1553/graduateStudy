1.1 为什么是 ML 策略？（Why ML Strategy?）
比如，你可能想我们去收集更多的训练数据吧。或者你会说，可能你的训练集的多样性还不够，你应该收集更多不同姿势的猫咪图片，或者更多样化的反例集。
或者你想再用梯度下降训练算法，训练久一点。或者你想尝试用一个完全不同的优化算法，比如 Adam 优化算法。或者尝试使用规模更大或者更小的神经网络。或者你想试试 dropout 或者𝐿2正则化。
或者你想修改网络的架构，比如修改激活函数，改变隐藏单元的数目之类的方法。

在这门课程中，可以教给你们一些策略，一些分析机器学习问题的方法，可以指引你们朝着最有希望的方向前进。这门课中，我会和你们分享我在搭建和部署大量深度学习
产品时学到的经验和教训，我想这些内容是这门课程独有的。比如说，很多大学深度学习课程很少提到这些策略。事实上，机器学习策略在深度学习的时代也在变化，因为现在对于深
度学习算法来说能够做到的事情，比上一代机器学习算法大不一样。我希望这些策略能帮助你们提高效率，让你们的深度学习系统更快投入实用。

1.2 正交化（Orthogonalization）
Example：正交化
这是一张老式电视图片，有很多旋钮可以用来调整图像的各种性质，所以对于这些旧式电视，可能有一个旋钮用来调图像垂直方向的高度，另外有一个旋钮用来调图像宽度，也许
还有一个旋钮用来调梯形角度，还有一个旋钮用来调整图像左右偏移，还有一个旋钮用来调图像旋转角度之类的。电视设计师花了大量时间设计电路，那时通常都是模拟电路来确保每
个旋钮都有相对明确的功能。如一个旋钮来调整这个（高度），一个旋钮调整这个（宽度），一个旋钮调整这个（梯形角度），以此类推。

相比之下，想象一下，如果你有一个旋钮调的是0.1𝑥表示图像高度，+0.3𝑥表示图像宽度，−1.7𝑥表示梯形角度，+0.8𝑥表示图像在水平轴上的坐标之类的。如果你调整这个（其中
一个）旋钮，那么图像的高度、宽度、梯形角度、平移位置全部都会同时改变，如果你有这样的旋钮，那几乎不可能把电视调好，让图像显示在区域正中。

所以在这种情况下，正交化指的是电视设计师设计这样的旋钮，使得每个旋钮都只调整一个性质，这样调整电视图像就容易得多，就可以把图像调到正中。

总结：正交化使得某个功能只能惟一的控制某一个属性。所以正交化的概念是指，你可以想出一个维度，这个维度你想做的是控制转向角，还有另一个维度来控制你的速度，
那么你就需要一个旋钮尽量只控制转向角，另一个旋钮，在这个开车的例子里其实是油门和刹车控制了你的速度。但如果你有一个控制旋钮将两者混在一起，
比如说这样一个控制装置同时影响你的转向角和速度，同时改变了两个性质，那么就很难令你的车子以想要的速度和角度前进。然而正交化之后，正交意味着互成 90 度。
设计出正交化的控制装置，最理想的情况是和你实际想控制的性质一致，这样你调整参数时就容易得多。

那么这与机器学习有什么关系呢？要弄好一个监督学习系统，你通常需要调你的系统的旋钮。

四个具体的问题：
Fit training set well on cost function
Fit dev(validation set) well on cost function
Fit test set well on cost function
Performs well in real world

确保四件事情：
（1）首先，你通常必须确保至少系统在训练集上得到的结果不错，所以训练集上的表现必须通过某种评估，达到能接受的程度，对于某些应用，这可能意味着达到人类
水平的表现，但这取决于你的应用，我们将在下周更多地谈谈如何与人类水平的表现进行比较。但是，在训练集上表现不错之后，你就希望系统也能在开发集上有好的表现，然后你希
望系统在测试集上也有好的表现。在最后，你希望系统在测试集上系统的成本函数在实际使用中表现令人满意，比如说，你希望这些猫图片应用的用户满意。
我们回到电视调节的例子，如果你的电视图像太宽或太窄，你想要一个旋钮去调整，你可不想要仔细调节五个不同的旋钮，它们也会影响别的图像性质，你只需要一个旋钮去改变电视图像的宽度。
所以类似地，如果你的算法在成本函数上不能很好地拟合训练集，你想要一个旋钮，是的我画这东西表示旋钮，或者一组特定的旋钮，这样你可以用来确保你的可以调整你的算法，
让它很好地拟合训练集，所以你用来调试的旋钮是你可能可以训练更大的网络，或者可以切换到更好的优化算法，比如 Adam 优化算法。

（2）相比之下，如果发现算法对开发集的拟合很差，那么应该有独立的一组旋钮，是的，这就是我画得毛毛躁躁的另一个旋钮，你希望有一组独立的旋钮去调试。比如说，你的算法在
开发集上做的不好，它在训练集上做得很好，但开发集不行，然后你有一组正则化的旋钮可以调节，尝试让系统满足第二个条件。类比到电视，就是现在你调好了电视的宽度，如果图
像的高度不太对，你就需要一个不同的旋钮来调节电视图像的高度，然后你希望这个旋钮尽量不会影响到电视的宽度。增大训练集可以是另一个可用的旋钮，它可以帮助你的学习算法
更好地归纳开发集的规律，现在调好了电视图像的高度和宽度。

（3）如果它不符合第三个标准呢？如果系统在开发集上做的很好，但测试集上做得不好呢？如果是这样，那么你需要调的旋钮，可能是更大的开发集。因为如果它在开发集上做的不错，
但测试集不行这可能意味着你对开发集过拟合了，你需要往回退一步，使用更大的开发集。

（4）最后，如果它在测试集上做得很好，但无法给你的猫图片应用用户提供良好的体验，这意味着你需要回去，改变开发集或成本函数。因为如果根据某个成本函数，系统在测试集上
做的很好，但它无法反映你的算法在现实世界中的表现，这意味着要么你的开发集分布设置不正确，要么你的成本函数测量的指标不对。

训练神经网络时，我一般不用 early stopping，这个技巧也还不错，很多人都这么干。但个人而言，我觉得早期停止有点难以分析，因为这个旋钮会同时影响你对训练集的拟
合，因为如果你用 early stopping，那么对训练集的拟合就不太好，但它同时也用来改善开发集的表现，所以这个旋钮没那么正交化。因为它同时影响两件事情，就像一个旋钮同时影响
电视图像的宽度和高度。不是说这样就不要用，如果你想用也是可以的。但如果你有更多的正交化控制，比如我这里写出的其他手段，用这些手段调网络会简单不少。

所以我希望你们对正交化的意义有点概念，就像你看电视图像一样。如果你说，我的电视图像太宽，所以我要调整这个旋钮（宽度旋钮）。或者它太高了，所以我要调整那个旋钮
（高度旋钮）。或者它太梯形了，所以我要调整这个旋钮（梯形角度旋钮），这就很好。在机器学习中，如果你可以观察你的系统，然后说这一部分是错的，它在训练集上做的
不好、在开发集上做的不好、它在测试集上做的不好，或者它在测试集上做的不错，但在现实世界中不好，这就很好。必须弄清楚到底是什么地方出问题了，然后我们刚好有对应的旋
钮，或者一组对应的旋钮，刚好可以解决那个问题，那个限制了机器学习系统性能的问题。

关键问题:如何诊断出系统性能瓶颈到底在哪。还有找到你可以用的一组特定的旋钮来调整你的系统，来改善它特定方面的性能。

1.3 单一数字评估指标（Single number evaluation metric）
查准率和查全率：
查准率的定义是在你的分类器标记为猫的例子中，有多少真的是猫。所以如果分类器𝐴有 95%的查准率，这意味着你的分类器说这图有猫的时候，有 95%的机会真的是猫。
查全率就是，对于所有真猫的图片，你的分类器正确识别出了多少百分比。实际为猫的图片中，有多少被系统识别出来？如果分类器𝐴查全率是 90%，这意味着对于所有的图像，
比如说你的开发集都是真的猫图，分类器𝐴准确地分辨出了其中的 90%。

查准率和查全率之间往往需要折衷，两个指标都要顾及到。你希望得到的效果是，当你的分类器说某个东西是猫的时候，有很大的机会它真的是一只猫，但对于所有是猫的图片，你也希望系统能够将大部分分类为
猫，所以用查准率和查全率来评估分类器是比较合理的。

查准率和查全率评估可能会产生的问题：
如果分类器𝐴在查全率上表现更好，分类器𝐵在查准率上表现更好，你就无法判断哪个分类器更好。如果你尝试了很多不同想法，很多不同的超参数，你希望能够快速试验不仅仅是两个分类器，
也许是十几个分类器，快速选出“最好的”那个，这样你可以从那里出发再迭代。如果有两个评估指标，就很难去快速地二中选一或者十中选一，所以我并不推荐使用两个评估指标，查准率和查全率来选
择一个分类器。你只需要找到一个新的评估指标，能够结合查准率和查全率。

结合查准率和查全率的标准方法是所谓的𝐹1分数，𝐹1分数的细节并不重要。但非正式的，你可以认为这是查准率𝑃和查全率𝑅的平均值。𝐹1分数的定义是这个公式：
F1 = 2 / (1 / p + 1 / R) 即 F1 分数是P和R的调和平均数

有一个定义明确的开发集用来测量查准率和查全率，再加上这样一个单一数值评估指标，有时我叫单实数评估指标，能让你快速判断分类器𝐴或者分类器𝐵更好。所以有这样一个开发集，
加上单实数评估指标，你的迭代速度肯定会很快，它可以加速改进您的机器学习算法的迭代过程。（例：使用错误率的平均值来评估算法）

1.4 满足和优化指标（Satisficing and optimizing metrics）
要把你顾及到的所有事情组合成单实数评估指标有时并不容易，在那些情况里，我发现有时候设立满足和优化指标是很重要的。
假设你已经决定你很看重猫分类器的分类准确度，这可以是𝐹1分数或者用其他衡量准确度的指标。但除了准确度之外，我们还需要考虑运行时间，就是需要多长时间来分类一张图。
分类器𝐴需要 80 毫秒，𝐵需要 95 毫秒，𝐶需要 1500 毫秒，就是说需要 1.5 秒来分类图像。

你可以这么做，将准确度和运行时间组合成一个整体评估指标。所以成本，比如说，总体成本是𝑐𝑜𝑠𝑡 = 𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦 − 0.5 × runningTime，这种组合方式可能太刻意，只用这样的公
式来组合准确度和运行时间，两个数值的线性加权求和。

你还可以做其他事情，就是你可能选择一个分类器，能够最大限度提高准确度，但必须满足运行时间要求，就是对图像进行分类所需的时间必须小于等于 100 毫秒。所以在这种情
况下，我们就说准确度是一个优化指标，因为你想要准确度最大化，你想做的尽可能准确，但是运行时间就是我们所说的满足指标，意思是它必须足够好，它只需要小于 100 毫秒，达
到之后，你不在乎这指标有多好，或者至少你不会那么在乎。所以这是一个相当合理的权衡方式，或者说将准确度和运行时间结合起来的方式。实际情况可能是，只要运行时间少于 100
毫秒，你的用户就不会在乎运行时间是 100 毫秒还是 50 毫秒，甚至更快。
通过定义优化和满足指标，就可以给你提供一个明确的方式，去选择“最好的”分类器。在这种情况下分类器 B 最好，因为在所有的运行时间都小于 100 毫秒的分类器中，它的准确度最好。

所以更一般地说，如果你要考虑𝑁个指标，有时候选择其中一个指标做为优化指标是合理的。所以你想尽量优化那个指标，然后剩下𝑁 − 1个指标都是满足指标，意味着只要它们
达到一定阈值，例如运行时间快于 100 毫秒，但只要达到一定的阈值，你不在乎它超过那个门槛之后的表现，但它们必须达到这个门槛。

例子:唤醒词的准确度与其假阳性指标
触发字检测系统的准确性，所以当有人说出其中一个触发词时，有多大概率可以唤醒你的设备。
假阳性（false positive）的数量，就是没有人在说这个触发词时，它被随机唤醒的概率有多大？所以这种情况下，组合这两种评估指标的合理方式可能是最大化精确度。所以当某人说出唤醒词时，
你的设备被唤醒的概率最大化，然后必须满足 24 小时内最多只能有 1 次假阳性，对吧？所以你的设备平均每天只会没有人真的在说话时随机唤醒一次。所以在这种情况下，准确度是优化指标，
然后每 24 小时发生一次假阳性是满足指标，你只要每 24 小时最多有一次假阳性就满足了。

1.5 训练/开发/测试集划分（Train/dev/test distributions）
如何设立开发集和测试集，开发（dev）集也叫做（development set），有时称为保留交叉验证集（hold out cross validation set）。然后，机器学习中的工作流程是，你尝试很多思路，
用训练集训练不同的模型，然后使用开发集来评估不同的思路，然后选择一个，然后不断迭代去改善开发集的性能，直到最后你可以得到一个令你满意的成本，然后你再用测试集去评估。

例子：开发一个猫分类器，然后你在这些区域里运营，美国、英国、其他欧洲国家，南美洲、印度、中国，其他亚洲国家和澳大利亚，那么你应该如何设立开发集和测试集呢？
错误的示范：选择其中 4 个区域，我打算使用这四个（前四个），但也可以是随机选的区域，来自这四个区域的数据构成开发集。然后其他四个区域，我打算用后四个，也可以随机选择 4 个，这些数据构成测试集。

原因：来自不同地区的数据可能会产生非常大的区别，因此训练出来的模型在新的验证集和测试集上的表现可能会很不好。
改进的做法：让开发集和测试集来自同一分布。将所有数据随机洗牌，放入开发集和测试集，所以开发集和测试集都有来自八个地区的数据，并且开发集和测试集都来自同一分布，这分
布就是你的所有数据混在一起。

真实的故事：有一个机器学习团队，花了好几个月在开发集上优化，开发集里面有中等收入邮政编码的贷款审批数据。那么具体的机器学习问题是，输入𝑥为贷款申请，你是否可以预测输出𝑦，𝑦是他们有没有还
贷能力？所以这系统能帮助银行判断是否批准贷款。所以开发集来自贷款申请，这些贷款申请来自中等收入邮政编码，zip code 就是美国的邮政编码。但是在这上面训练了几个月之后，
团队突然决定要在，低收入邮政编码数据上测试一下。当然了，这个分布数据里面中等收入和低收入邮政编码数据是很不一样的，而且他们花了大量时间针对前面那组数据优化分类
器，导致系统在后面那组数据中效果很差。所以这个特定团队实际上浪费了 3 个月的时间，不得不退回去重新做很多工作。（即，在选择验证集和测试集时一定要注意是否来自同一分布）

做法：
在设立开发集和测试集时，要选择这样的开发集和测试集，能够反映你未来会得到的数据，认为很重要的数据，必须得到好结果的数据，特别是，这里的开发集和测试集可能来自同一个分布。
所以不管你未来会得到什么样的数据，一旦你的算法效果不错，要尝试收集类似的数据，而且，不管那些数据是什么，都要随机分配到开发集和测试集上。因为这样，你才能将瞄准想要的目标，
让你的团队高效迭代来逼近同一个目标，希望最好是同一个目标。

1.6 开发集和测试集的大小（Size of dev and test sets）
开发集（验证集）是不可或缺的，一般没有测试集的时候可以直接在开发集上进行测试。
训练集和验证集的大小在数据量比较小的时候可以设置为7比3，在有测试集的时候可以设置为3比1比1
现在数据量非常大的情况下，几百万条数据中99％都可以设置为训练集，测试集和验证集的大小只需要占到1%即可。

1.7 什么时候该改变开发/测试集和指标？（When to change dev/test sets and metrics）
例子：在完善猫分类器的时候，假设以A分类器和B分类器的准确度作为评价指标，A的错误率更少，但是A分类器不能作为更好的分类选择。

解释：评价指标如果只是单一的准确率，其在推送不同内容时的权重应该有所区别。例如A分类器给用户推送色情图片就是无法容忍的准确率错误，因此应该赋予比较高的错误权重。
原准确性错误指标：𝐸𝑟𝑟𝑜𝑟 = 1 / 𝑚 sub(𝑑𝑒𝑣) ∑ 𝐼{𝑦 𝑝𝑟𝑒𝑑(𝑖) ≠ 𝑦(𝑖)}
修正后的准确性错误指标：𝐸𝑟𝑟𝑜𝑟 = 1 / 𝑚 sub(𝑑𝑒𝑣) ∑ 𝑤(𝑖) * 𝐼{𝑦 𝑝𝑟𝑒𝑑(𝑖) ≠ 𝑦(𝑖)}
这样我们可以赋予不同的准确性错误不同的权重从而产生更准确的准确性错误指标

如果你希望得到归一化常数，在技术上，就是𝑤(𝑖)对所有𝑖求和，这样错误率仍然在 0 和 1 之间，即：
𝐸𝑟𝑟𝑜𝑟 = 1 / ∑ w(i) * ∑ 𝑤(𝑖) * 𝐼{𝑦 𝑝𝑟𝑒𝑑(𝑖) ≠ 𝑦(𝑖)} 
加权的细节并不重要，实际上要使用这种加权，你必须自己过一遍开发集和测试集，在开发集和测试集里，自己把色情图片标记出来，这样你才能使用这个加权函数。

粗略的结论是，如果你的评估指标无法正确评估好算法的排名，那么就需要花时间定义一个新的评估指标。这是定义评估指标的其中一种可能方式（上述加权法）。评估指标的
意义在于，准确告诉你已知两个分类器，哪一个更适合你的应用。就这个视频的内容而言，我们不需要太注重新错误率指标是怎么定义的，关键在于，如果你对旧的错误率指标不满意，
那就不要一直沿用你不满意的错误率指标，而应该尝试定义一个新的指标，能够更加符合你的偏好，定义出实际更适合的算法。
到目前为止我们只讨论了如何定义一个指标去评估分类器，也就是说，我们定义了一个评估指标帮助我们更好的把分类器排序，能够区分出它们在识别色情图片的不同水平，这实际上是一个正交化的例子。

处理机器学习问题时，应该把它切分成独立的步骤。一步是弄清楚如何定义一个指标来衡量你想做的事情的表现，然后我们可以分开考虑如何改善系统在这个指标上的表现。
你们要把机器学习任务看成两个独立的步骤，用目标这个比喻，第一步就是设定目标。所以要定义你要瞄准的目标，这是完全独立的一步，这是你可以调节的一个旋钮。如何设立
目标是一个完全独立的问题，把它看成是一个单独的旋钮，可以调试算法表现的旋钮，如何精确瞄准，如何命中目标，定义指标是第一步。

然后第二步要做别的事情，在逼近目标的时候，也许你的学习算法针对某个长这样的成本函数优化，𝐽 = 1 / 𝑚 ∑ 𝐿(𝑦^(𝑖) , 𝑦(𝑖)) ，你要最小化训练集上的损失。你可以做的其中一件事
是，修改这个，为了引入这些权重，也许最后需要修改这个归一化常数，即𝐽 = 1 / ∑𝑤(𝑖) * ∑ 𝑤(𝑖) * 𝐿(𝑦^(𝑖) , 𝑦(𝑖))
如何定义𝐽并不重要，关键在于正交化的思路，把设立目标定为第一步，然后瞄准和射击目标是独立的第二步。换种说法，我鼓励你们将定义指标看成一步，然后在定义了
指标之后，你才能想如何优化系统来提高这个指标评分。比如改变你神经网络要优化的成本函数𝐽。

例子2：。假设你的两个猫分类器𝐴和𝐵，分别有用开发集评估得到 3%的错误率和 5%的错误率。或者甚至用在网上下载的图片构成的测试集上，这些是高
质量，取景框很专业的图像。但也许你在部署算法产品时，你发现算法𝐵看起来表现更好，即使它在开发集上表现不错，你发现你一直在用从网上下载的高质量图片训练，但当你部署
到手机应用时，算法作用到用户上传的图片时，那些图片取景不专业，没有把猫完整拍下来，或者猫的表情很古怪，也许图像很模糊，当你实际测试算法时，你发现算法𝐵表现其实更好。

这是另一个指标和开发集测试集出问题的例子，问题在于，你做评估用的是很漂亮的高分辨率的开发集和测试集，图片取景很专业。但你的用户真正关心的是，他们上传的图片能
不能被正确识别。那些图片可能是没那么专业的照片，有点模糊，取景很业余。所以方针是，如果你在指标上表现很好，在当前开发集或者开发集和测试集分布中表现
很好，但你的实际应用程序，你真正关注的地方表现不好，那么就需要修改指标或者你的开发测试集。换句话说，如果你发现你的开发测试集都是这些高质量图像，但在开发测试集上
做的评估无法预测你的应用实际的表现。因为你的应用处理的是低质量图像，那么就应该改变你的开发测试集，让你的数据更能反映你实际需要处理好的数据。
但总体方针就是，如果你当前的指标和当前用来评估的数据和你真正关心必须做好的事情关系不大，那就应该更改你的指标或者你的开发测试集，让它们能更够好地反映你的算法
需要处理好的数据。

有一个评估指标和开发集让你可以更快做出决策，判断算法𝐴还是算法𝐵更优，这真的可以加速你和你的团队迭代的速度。所以我的建议是，即使你无法定义出一个很完美的评估
指标和开发集，你直接快速设立出来，然后使用它们来驱动你们团队的迭代速度。如果在这之后，你发现选的不好，你有更好的想法，那么完全可以马上改。对于大多数团队，我建议
最好不要在没有评估指标和开发集时跑太久，因为那样可能会减慢你的团队迭代和改善算法的速度。本视频讲的是什么时候需要改变你的评估指标和开发测试集，我希望这些方针能让
你的整个团队设立一个明确的目标，一个你们可以高效迭代，改善性能的目标。

总结：可以在最开始就选取一个评估指标，以评估指标为目标来优化分类器。如果发现评估指标拟合的不好可以再进行修改。但首先，根本的我们需要一个指导性的标准。

1.8 为什么是人的表现？（Why human-level performance?）
两个主要原因，首先是因为深度学习系统的进步，机器学习算法突然变得更好了。在许多机器学习的应用领域已经开始见到算法已经可以威胁到人类的表现了。其次，事实证明，
当你试图让机器做人类能做的事情时，可以精心设计机器学习系统的工作流程，让工作流程效率更高，所以在这些场合，比较人类和机器是很自然的，或者你要让机器模仿人类的行为。

在这些时间里，一些团队或一些研究小组正在研究一个问题，当你开始往人类水平努力时，进展是很快的。但是过了一段时间，当这个算法表现比人类更好时，那么进展和精确度的提升就变得更慢了。
也许它还会越来越好，但是在超越人类水平之后，它还可以变得更好，但性能增速，准确度上升的速度这个斜率，会变得越来越平缓，我们都希望能达到理论最佳性能水平。随着时间的推移，
当您继续训练算法时，可能模型越来越大，数据越来越多，但是性能无法超过某个理论上限，这就是所谓的贝叶斯最优错误率（Bayes optimal error）。所以贝叶斯最优错误率一般认为是
理论上可能达到的最优错误率，就是说没有任何办法设计出一个𝑥到𝑦的函数，让它能够超过一定的准确度。贝叶斯最优错误率有时写作 Bayesian，即省略 optimal，就是从𝑥到𝑦映射的理论最优
函数，永远不会被超越。

事实证明，机器学习的进展往往相当快，直到你超越人类的表现之前一直很快，当你超越人类的表现时，有时进展会变慢。我认为有两个原因，为什么当你超越人类的表现时，进
展会慢下来。一个原因是人类水平在很多任务中离贝叶斯最优错误率已经不远了，人们非常擅长看图像，分辨里面有没有猫或者听写音频。所以，当你超越人类的表现之后也许没有太
多的空间继续改善了。但第二个原因是，只要你的表现比人类的表现更差，那么实际上可以使用某些工具来提高性能。一旦你超越了人类的表现，这些工具就没那么好用了。
对于人类相当擅长的任务，包括看图识别事物，听写音频，或阅读语言，人类一般很擅长处理这些自然数据。对于人类擅长的任务，只要你的机器学习算法比人类差，你就可以从让人帮你标记数据，
你可以让人帮忙或者花钱请人帮你标记例子，这样你就有更多的数据可以喂给学习算法。下周我们会讨论，人工错误率分析，但只要人类的表现比任何其他算法都要好，你就可以让人类看看你算法处理的例子，
知道错误出在哪里，并尝试了解为什么人能做对，算法做错。下周我们会看到，这样做有助于提高算法的性能。你也可以更好地分析偏差和方差，我们稍后会谈一谈。但是只要你的算法仍然比人类糟糕，
你就有这些重要策略可以改善算法。而一旦你的算法做得比人类好，这三种策略就很难利用了。所以这可能是另一个和人类表现比较的好处，特别是在人类做得很好的任务上。

为什么机器学习算法往往很擅长模仿人类能做的事情，然后赶上甚至超越人类的表现。特别是，即使你知道偏差是多少，方差是多少。知道人类在特定任务上能做多好可以帮助你
更好地了解你应该重点尝试减少偏差，还是减少方差。

1.9 可避免偏差（Avoidable bias）
我们经常使用猫分类器来做例子，比如人类具有近乎完美的准确度，所以人类水平的错误是 1%。在这种情况下，如果您的学习算法达到 8%的训练错误率和 10%的开发错误率，那
么你也许想在训练集上得到更好的结果。所以事实上，你的算法在训练集上的表现和人类水平的表现有很大差距的话，说明你的算法对训练集的拟合并不好。所以从减少偏差和方差的
工具这个角度看，在这种情况下，我会把重点放在减少偏差上。你需要做的是，比如说训练更大的神经网络，或者跑久一点梯度下降，就试试能不能在训练集上做得更好。

减少偏差：训练更大的神经网络，跑久一点梯度下降（more epochs） 这时的神经网络还有提升的空间，其拟合还可以更好，可以向着人类的分辨错误率改进。

但现在我们看看同样的训练错误率和开发错误率，假设人类的表现不是 1%，我们就把它抄写过来。但你知道，在不同的应用或者说用在不同的数据集上，假设人类水平错误实际
上是 7.5%，也许你的数据集中的图像非常模糊，即使人类都无法判断这张照片中有没有猫。这个例子可能稍微更复杂一些，因为人类其实很擅长看照片，分辨出照片里有没有猫。但就
为了举这个例子，比如说你的数据集中的图像非常模糊，分辨率很低，即使人类错误率也达到 7.5%。在这种情况下，即使你的训练错误率和开发错误率和其他例子里一样，你就知道，
也许你的系统在训练集上的表现还好，它只是比人类的表现差一点点。在第二个例子中，你可能希望专注减少这个分量，减少学习算法的方差，也许你可以试试正则化，让你的开发错
误率更接近你的训练错误率。

减少方差：正则化，收集更多的数据。 在人类错误率也比较高的场合，神经网络应该尽量减少方差从而增加稳定性，此时难以再减少错误率到人的水平。如果要再减少错误应该尝试其他的方法。

总之，贝叶斯最优错误率应该是一个虚拟的标准，其表明最优的错误率标准如何，并不值得我们一直朝着这个最佳错误率的方向努力。在很多情况下，如果人的识别错误率也近似等于贝叶斯错误率时，
我们应该首先将人的识别错误率作为一个比较好的优化目标（人在识别图片或者音频等非结构化的数据时的表现是比较好的，可以近似对贝叶斯最优错误率替换）。此时我们应该把优化目标转为减少
偏差到人为识别错误率上，对于错误率近似人为错误率或者贝叶斯最优错误率的分类器，我们应该将目标值转为优化两个分类器的方差。

贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为可避免偏差。（意思就是与最好的错误率的差距都是可以优化的偏差）

可避免偏差这个词说明了有一些别的偏差，或者错误率有个无法超越的最低水平，那就是说如果贝叶斯错误率是 7.5%。你实际上并不想得到低于该级别的错误率，所以你不会说
你的训练错误率是 8%，然后 8%就衡量了例子中的偏差大小。你应该说，可避免偏差可能在0.5%左右，或者 0.5%是可避免偏差的指标。而这个 2%是方差的指标，所以要减少这个 2%
比减少这个 0.5%空间要大得多。而在左边的例子中，这 7%衡量了可避免偏差大小，而 2%衡量了方差大小。所以在左边这个例子里，专注减少可避免偏差可能潜力更大。
（这里的方差的概念实际上就是验证集和训练集误差的差值）

1.10 理解人的表现（Understanding human-level performance）
例子：假设你要观察这样的放射科图像，然后作出分类诊断，假设一个普通的人类，未经训练的人类，在此任务上达到 3%的错误率。普通的医生，也许是普通的放射科医生，能达到 1%
的错误率。经验丰富的医生做得更好，错误率为 0.7%。还有一队经验丰富的医生，就是说如果你有一个经验丰富的医生团队，让他们都看看这个图像，然后讨论并辩论，他们达成共识
的意见达到 0.5%的错误率。所以我想问你的问题是，你应该如何界定人类水平错误率？人类水平错误率 3%,1%, 0.7%还是 0.5%？
思考人类水平错误率最有用的方式之一是，把它作为贝叶斯错误率的替代或估计。

结论：用最小的人类水平错误率来估计贝叶斯错误率，因为贝叶斯错误率是小于所有可求错误率的，这是一个最优的标准。但是这只是说明了贝叶斯最优错误率的最大值小于0.5%，真正的贝叶斯最优错误率
可能是难以求出的，因此我们用最优的人类水平错误率来逼近贝叶斯最优错误率。

要了解为什么这个很重要，我们来看一个错误率分析的例子。比方说，在医学图像诊断例子中，你的训练错误率是 5%，你的开发错误率是 6%。而在上一张幻灯片的例子中，我们
的人类水平表现，我将它看成是贝叶斯错误率的替代品，取决于你是否将它定义成普通单个医生的表现，还是有经验的医生或医生团队的表现，你可能会用 1%或 0.7%或 0.5%。同时也
回想一下，前面视频中的定义，贝叶斯错误率或者说贝叶斯错误率的估计和训练错误率直接的差值就衡量了所谓的可避免偏差，这（训练误差与开发误差之间的差值）可以衡量或者估
计你的学习算法的方差问题有多严重。

所以在这个第一个例子中，无论你做出哪些选择，可避免偏差大概是 4%，这个值我想介于……，如果你取 1%就是 4%，如果你取 0.5%就是 4.5%，而这个差距（训练误差与开发误差之间的差值）
是 1%。所以在这个例子中，我得说，不管你怎么定义人类水平错误率，使用单个普通医生的错误率定义，还是单个经验丰富医生的错误率定义或经验丰富的医生团队的错误率定义，这是 4%还是 4.5%，
这明显比都比方差问题更大。所以在这种情况下，你应该专注于减少偏差的技术，例如培训练更大的网络。

现在来看看第二个例子，比如说你的训练错误率是 1%，开发错误率是 5%，这其实也不怎么重要，这种问题更像学术界讨论的，人类水平表现是 1%或 0.7%还是 0.5%。因为不管你
使用哪一个定义，你测量可避免偏差的方法是，如果用那个值，就是 0%到 0.5%之前，对吧？那就是人类水平和训练错误率之前的差距，而这个差距是 4%，所以这个 4%差距比任何一种
定义的可避免偏差都大。所以他们就建议，你应该主要使用减少方差的工具，比如正则化或者去获取更大的训练集。

什么时候真正有效呢?
就是比如你的训练错误率是 0.7%，所以你现在已经做得很好了，你的开发错误率是 0.8%。在这种情况下，你用 0.5%来估计贝叶斯错误率关系就很大。因为在这种情况下，你测量到
的可避免偏差是 0.2%，这是你测量到的方差问题 0.1%的两倍，这表明也许偏差和方差都存在问题。但是，可避免偏差问题更严重。在这个例子中，我们在上一张幻灯片中讨论的是 0.5%，
就是对贝叶斯错误率的最佳估计，因为一群人类医生可以实现这一目标。如果你用 0.7 代替贝叶斯错误率，你测得的可避免偏差基本上是 0%，那你就可能忽略可避免偏差了。实际上
你应该试试能不能在训练集上做得更好。

为什么机器学习在达到或者接近人类水平时进展就会缓慢？
在这个例子中，一旦你接近 0.7%错误率，除非你非常小心估计贝叶斯错误率，你可能无法知道离贝叶斯错误率有多远，所以你应该尽量减少可避免偏差。事实上，如果你只知道
单个普通医生能达到 1%错误率，这可能很难知道是不是应该继续去拟合训练集，这种问题只会出现在你的算法已经做得很好的时候，只有你已经做到 0.7%, 0.8%, 接近人类水平时会出现。
而在左边的两个例子中，当你远离人类水平时，将优化目标放在偏差或方差上可能更容易一点。这就说明了，为什么当你们接近人类水平时，更难分辨出问题是偏差还是方差。
所以机器学习项目的进展在你已经做得很好的时候，很难更进一步。

总结一下我们讲到的，如果你想理解偏差和方差，那么在人类可以做得很好的任务中，你可以估计人类水平的错误率，你可以使用人类水平错误率来估计贝叶斯错误率。所以你到贝叶斯错误率估计值的差距，
告诉你可避免偏差问题有多大，可避免偏差问题有多严重，而训练错误率和开发错误率之间的差值告诉你方差上的问题有多大，你的算法是否能够从训练用这个值估计偏差。相比之下，在这个视频中，
我们有一个更微妙的分析，其中并没有假设你应该得到 0%错误率，因为有时贝叶斯错误率是非零的，有时基本不可能做到比某个错误率阈值更低。所以在之前的课程中，我们测量的是训练错误率，
然后观察的是训练错误率比0%高多少，就用这个差值来估计偏差有多大。而事实证明，对于贝叶斯错误率几乎是 0%的问题这样就行了，例如识别猫，人类表现接近完美，所以贝叶斯错误率也接近完美。
所以当贝叶斯错误率几乎为零时，可以那么做。但数据噪点很多时，比如背景声音很嘈杂的语言识别，有时几乎不可能听清楚说的是什么，并正确记录下来。对于这样的问题，更好的估计贝叶斯错误率很有必要，
可以帮助你更好地估计可避免偏差和方差，这样你就能更好的做出决策，选择减少偏差的策略，还是减少方差的策略。

总结:选择一个合适的贝叶斯错误率（或者人类水平错误率）对分析问题是很有作用的，很多时候和0进行错误率的比较是不合适的，错误率的阈值是有下限的，因此有时候用人类水平错误率可以更好地指导
机器学习中的错误率指标应该优化的目标，从而更好的判断优化的目标（减小偏差还是减少方差）
对人类水平有大概的估计可以让你做出对贝叶斯错误率的估计，这样可以让你更快地作出决定是否应该专注于减少算法的偏差，或者减少算法的方差。这个决策技巧通常很有效，直到你的系统性能开始超越人类，
那么你对贝叶斯错误率的估计就不再准确了，但这些技巧还是可以帮你做出明确的决定。

1.11 超过人的表现（Surpassing human- level performance）
机器学习进展，会在接近或者超越人类水平的时候变得越来越慢。
例子：假设你有一个问题，一组人类专家充分讨论辩论之后，达到 0.5%的错误率，单个人类专家错误率是 1%，然后你训练出来的算法有 0.6%的训练错误率，0.8%的开发错误率。所以
在这种情况下，可避免偏差是多少？这个比较容易回答，0.5%是你对贝叶斯错误率的估计，所以可避免偏差就是 0.1%。你不会用这个 1%的数字作为参考，你用的是这个差值，所以也
许你对可避免偏差的估计是至少 0.1%，然后方差是 0.2%。和减少可避免偏差比较起来，减少方差可能空间更大。

但现在我们来看一个比较难的例子，一个人类专家团和单个人类专家的表现和以前一样，但你的算法可以得到 0.3%训练错误率，还有 0.4%开发错误率。现在，可避免偏差是什么呢？
现在其实很难回答，事实上你的训练错误率是 0.3%，这是否意味着你过拟合了 0.2%，或者说贝叶斯错误率其实是 0.1%呢？或者也许贝叶斯错误率是 0.2%？或者贝叶斯错误率是 0.3%
呢？你真的不知道。但是基于本例中给出的信息，你实际上没有足够的信息来判断优化你的算法时应该专注减少偏差还是减少方差，这样你取得进展的效率就会降低。还有比如说，如
果你的错误率已经比一群充分讨论辩论后的人类专家更低，那么依靠人类直觉去判断你的算法还能往什么方向优化就很难了。所以在这个例子中，一旦你超过这个 0.5%的门槛，要进
一步优化你的机器学习问题就没有明确的选项和前进的方向了。这并不意味着你不能取得进展，你仍然可以取得重大进展。但现有的一些工具帮助你指明方向的工具就没那么好用了。

为什么在某些领域机器学习的表现比人类更加优秀：
请注意这四个例子，所有这四个例子都是从结构化数据中学习得来的，这里你可能有个数据库记录用户点击的历史，你的购物历史数据库，或者从𝐴到𝐵需要多长时间的数据库，
以前的贷款申请及结果的数据库，这些并不是自然感知问题，这些不是计算机视觉问题，或语音识别，或自然语言处理任务。人类在自然感知任务中往往表现非常好，所以有可能对计
算机来说在自然感知任务的表现要超越人类要更难一些。（即人类对非结构化信息的感知要比结构化信息更加优秀，因此在处理结构化信息的时候机器要更加敏感和优秀）
最后，这些问题中，机器学习团队都可以访问大量数据，所以比如说，那四个应用中，最好的系统看到的数据量可能比任何人类能看到的都多，所以这样就相对容易得到超越人类
水平的系统。现在计算机可以检索那么多数据，它可以比人类更敏锐地识别出数据中的统计规律。

除了这些问题，今天已经有语音识别系统超越人类水平了，还有一些计算机视觉任务，一些图像识别任务，计算机已经超越了人类水平。但是由于人类对这种自然感知任务非常擅
长，我想计算机达到那种水平要难得多。还有一些医疗方面的任务，比如阅读 ECG 或诊断皮肤癌，或者某些特定领域的放射科读图任务，这些任务计算机做得非常好了，也许超越了单个人类的水平。、

在深度学习的最新进展中，其中一个振奋人心的方面是，即使在自然感知任务中，在某些情况下，计算机已经可以超越人类的水平了。不过现在肯定更加困难，因为人类一般很擅长这种自然感知任务。
所以要达到超越人类的表现往往不容易，但如果有足够多的数据，已经有很多深度学习系统，在单一监督学习问题上已经超越了人类的水平，所以这对你在开发的应用是有意义的。

1.12 改善你的模型的表现 （Improving your model performance）
你们学过正交化，如何设立开发集和测试集，用人类水平错误率来估计贝叶斯错误率以及如何估计可避免偏差和方差。我们现在把它们全部组合起来写成一套指导方针，如何提高学习算法性能的指导方针。

所以我想要让一个监督学习算法达到实用，基本上希望或者假设你可以完成两件事情。
首先，你的算法对训练集的拟合很好，这可以看成是你能做到可避免偏差很低。还有第二件事你可以做好的是，在训练集中做得很好，然后推广到开发集和测试集也很好，这就是说方差不是太大。

在正交化的精神下，你可以看到这里有第二组旋钮，可以修正可避免偏差问题，比如训练更大的网络或者训练更久。还有一套独立的技巧可以用来处理方差问题，比如正则化或者收集更多训练数据。
总结一下前几段视频我们见到的步骤，如果你想提升机器学习系统的性能，我建议你们看看训练错误率和贝叶斯错误率估计值之间的距离，让你知道可避免偏差有多大。换句话说，
就是你觉得还能做多好，你对训练集的优化还有多少空间。然后看看你的开发错误率和训练错误率之间的距离，就知道你的方差问题有多大。换句话说，你应该做多少努力让你的算法
表现能够从训练集推广到开发集，算法是没有在开发集上训练的。

减少可避免方差的方法：
（1）使用规模更大的模型，这样算法在训练集上的表现会更好，或者训练更久。
（2）使用更好的优化算法，比如说加入 momentum 或者 RMSprop，或者使用更好的算法，比如 Adam。
（3）你还可以试试寻找更好的新神经网络架构，或者说更好的超参数。
（4）你可以改变激活函数，改变层数或者隐藏单位数，虽然你这么做可能会让模型规模变大。
（5）试用其他模型，其他架构，如循环神经网络和卷积神经网络。新的神经网络架构能否更好地拟合你的训练集，有时也很难预先判断，但有时换架构可能会得到好得多的结果。

减少方法的方法：
（1）你可以收集更多数据，因为收集更多数据去训练可以帮你更好地推广到系统看不到的开发集数据。
（2）你可以尝试正则化，包括𝐿2正则化，dropout 正则化或者我们在之前课程中提到的数据增强。
（3）你也可以试用不同的神经网络架构，超参数搜索，看看能不能帮助你，找到一个更适合你的问题的神经网络架构。


















