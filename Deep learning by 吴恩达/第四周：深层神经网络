4.1 深层神经网络(Deep Neural Networks)
  拥有多个隐藏层的神经网络称为深层神经网络。

  回顾：神经网络层数的定义（layer），从左往右数依次为（0,1,2,3,4……）
  
  如何确定神经网络的层数：尽管对于任何给定的问题很难去提前预测到底需要多深的神经网络，所以先去尝试逻辑回归，尝试一层然后两层隐含层，然后把隐含层的数量看做是另一个可以自由选择大小的超参数，
  然后再保留交叉验证数据上评估，或者用你的开发集来评估。（有一些函数只能由深层神经网络学会）
  
  神经网络中的符号约定：
    输入的特征记为x，由于x是输入层的激活函数，因此x = a[0]
    用L表示神经网络拥有的layer数量，例如L = 4，其中的层数用l代指，本例中l的取值为（0,1,2,3），每一层的激活函数产生的结果记为a[l]
    每一层中使用激活函数g对z[l]计算出结果a[l],其中w[l]表示l层计算z值时的权重，b[l]表示l层计算z[l]值的偏置
    最后一层的激活函数a[L]产生的就是这个神经网络最后预测的输出结果。
  
4.2 前向传播和反向传播（Forward and backward propagation）
  前向传播：
    前向传播输入的参数是a[l-1]，产生的输出时a[l],产生的缓存是z[l](从实现的角度来说我们可以缓存下(𝑤[𝑙]和𝑏[𝑙]，这样更容易在不同的环节中调用函数)
    
    前向传播的步骤:
    𝑧[𝑙] = 𝑊[𝑙] · 𝑎[𝑙−1] + 𝑏[𝑙] · 𝑎[𝑙] = 𝑔[𝑙](𝑧[𝑙])  
    向量化实现过程可以写成： 𝑧[𝑙] = 𝑊[𝑙] · 𝐴[𝑙−1] + 𝑏[𝑙] · 𝐴[𝑙] = 𝑔[𝑙](𝑍[𝑙])
  
  反向传播：
    
