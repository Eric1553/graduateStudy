3.1 调试处理（Tuning process）
关于训练深度最难的事情之一是你要处理的参数的数量，从学习速率𝑎到 Momentum（动量梯度下降法）的参数𝛽。如果使用 Momentum 或 Adam 优化算法的参数，𝛽1，𝛽2和𝜀，
也许你还得选择层数，也许你还得选择不同层中隐藏单元的数量，也许你还想使用学习率衰减。所以，你使用的不是单一的学习率𝑎。接着，当然你可能还需要选择 mini-batch 的大小。

最重要的超参数：a 学习率

除了𝑎，还有一些参数需要调试，例如 Momentum 参数𝛽，0.9 就是个很好的默认值。我还会调试 mini-batch 的大小，以确保最优算法运行有效。我还会经常调试隐藏单元，我用橙
色圈住的这些，这三个是我觉得其次比较重要的，相对于𝑎而言。重要性排第三位的是其他因素，层数有时会产生很大的影响，学习率衰减也是如此。当应用 Adam 算法时，事实上，
我从不调试𝛽1，𝛽2和𝜀，我总是选定其分别为 0.9，0.999 和10的−8，如果你想的话也可以调试。

Andrew NG认为的超参数的调整重要性：
a >> β = hidden units = mini-batch size > layers = learning rate decay >> β1（默认0.9） = β2（默认0.999） = ε（默认10的-8次方）

方法一：在超参数比较少的情况下，可以使用随机取样本点的方法尝试超参数的学习效果
现在，如果你尝试调整一些超参数，该如何选择调试值呢？在早一代的机器学习算法中，如果你有两个超参数，这里我会称之为超参 1，超参 2，常见的做法是在网格中取样点，像
这样，然后系统的研究这些数值。这里我放置的是 5×5 的网格，实践证明，网格可以是 5×5，也可多可少，但对于这个例子，你可以尝试这所有的 25 个点，然后选择哪个参数效果最好。
当参数的数量相对较少时，这个方法很实用。  

推荐你采用下面的做法，随机选择点，所以你可以选择同等数量的点。25 个点，接着，用这些随机取的点试验超参数的效果。之所以这么做是因为，对于你要解决的问题而言，
你很难提前知道哪个超参数最重要，正如你之前看到的，一些超参数的确要比其它的更重要。
举个例子，假设超参数 1 是𝑎（学习速率），取一个极端的例子，假设超参数 2 是 Adam算法中，分母中的𝜀。在这种情况下，𝑎的取值很重要，而𝜀取值则无关紧要。如果你在网格
中取点，接着，你试验了𝑎的 5 个取值，那你会发现，无论𝜀取何值，结果基本上都是一样的。所以，你知道共有 25 种模型，但进行试验的𝑎值只有 5 个，我认为这是很重要的。
对比而言，如果你随机取值，你会试验 25 个独立的𝑎，似乎你更有可能发现效果做好的那个。

实践中，你搜索的超参数可能不止两个。假如，你有三个超参数，这时你搜索的不是一个方格，而是一个立方体，超参数 3 代表第三维，接着，在
三维立方体中取值，你会试验大量的更多的值，三个超参数中每个都是。

实践中，你搜索的可能不止三个超参数有时很难预知，哪个是最重要的超参数，对于你的具体应用而言，随机取值而不是网格取值表明，你探究了更多重要超参数的潜在值，无论结果是什么。

给超参数取值时，另一个惯例是采用由粗糙到精细的策略。比如在二维的那个例子中，你进行了取值，也许你会发现效果最好的某个点，也许这个点周围的其他一些点效果也很好，
那在接下来要做的是放大这块小区域（小蓝色方框内），然后在其中更密集得取值或随机取值，聚集更多的资源，在这个蓝色的方格中搜索，如果你怀疑这些超参数在这个区域的最优结果，
那在整个的方格中进行粗略搜索后，你会知道接下来应该聚焦到更小的方格中。在更小的方格中，你可以更密集得取点。所以这种从粗到细的搜索也经常使用。

通过试验超参数的不同取值，你可以选择对训练集目标而言的最优值，或对于开发集而言的最优值，或在超参搜索过程中你最想优化的东西。

3.2 为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）
随机取值可以提升你的搜索效率。但随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺，用于探究这些超参数，这很重要。

你要选取隐藏单元的数量𝑛[𝑙]，假设，你选取的取值范围是从 50 到 100 中某点，这种情况下，看到这条从 50-100 的数轴，你可以随机在其取点，这是一个搜索特定超参数的
很直观的方式。或者，如果你要选取神经网络的层数，我们称之为字母𝐿，你也许会选择层数为 2 到 4 中的某个值，接着顺着 2，3，4 随机均匀取样才比较合理，你还可以应用网格搜
索，你会觉得 2，3，4，这三个数值是合理的，这是在几个在你考虑范围内随机均匀取值的例子，这些取值还蛮合理的，但对某些超参数而言不适用。

假设你在搜索超参数𝑎（学习速率），假设你怀疑其值最小是 0.0001 或最大是 1。如果 你画一条从 0.0001 到 1 的数轴，沿其随机均匀取值，那 90%的数值将会落在0.1 到 1 之间，
结果就是，在 0.1 到 1 之间，应用了 90%的资源，而在 0.0001 到 0.1 之间，只有 10%的搜索资源，这看上去不太对。反而，用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，
分别依次取0.0001，0.001，0.01，0.1，1，在对数轴上均匀随机取点，这样，在 0.0001 到 0.001 之间，就会有更多的搜索资源可用，还有在 0.001 到 0.01 之间等等。

在 Python 中，你可以这样做，使 r=-4*np.random.rand()，然后𝑎随机取值，𝑎 = 10𝑟，所以，第一行可以得出𝑟 ∈ [4,0]，那么𝑎 ∈ [10的−4, 100]，所以最左边的数字是10的−4，最右边是100。
更常见的情况是，如果你在10的𝑎和10的𝑏之间取值，在此例中，这是10的𝑎（0.0001），你可以通过0.0001算出𝑎的值，即-4，在右边的值是10𝑏，你可以算出𝑏的值1，即 0。你要做的就
是在[𝑎, 𝑏]区间随机均匀地给𝑟取值，这个例子中𝑟 ∈ [−4,0]，然后你可以设置𝑎的值，基于随机取样的超参数𝑎 = 10的𝑟。

所以总结一下，在对数坐标下取值，取最小值的对数就得到𝑎的值，取最大值的对数就得到𝑏值，所以现在你在对数轴上的10的𝑎到10的𝑏区间取值，在𝑎，𝑏间随意均匀的选取𝑟值，
将超参数设置为10的𝑟，这就是在对数轴上取值的过程。所以总结一下，在对数坐标下取值，取最小值的对数就得到𝑎的值，取最大值的对数就得到𝑏值，所以现在你在对数轴上的10的𝑎到10的𝑏区间取值，
在𝑎，𝑏间随意均匀的选取𝑟值，将超参数设置为10的𝑟，这就是在对数轴上取值的过程。

最后，另一个棘手的例子是给𝛽 取值，用于计算指数的加权平均值。假设你认为𝛽是 0.9到 0.999 之间的某个值，也许这就是你想搜索的范围。记住这一点，当计算指数的加权平均
值时，取 0.9 就像在 10 个值中计算平均值，有点类似于计算 10 天的温度平均值，而取 0.999就是在 1000 个值中取平均。所以和上张幻灯片上的内容类似，如果你想在 0.9 到 0.999 区间搜索，
那就不能用线性轴取值，对吧？不要随机均匀在此区间取值，所以考虑这个问题最好的方法就是，我们要探究的是1 − 𝛽，此值在 0.1 到 0.001 区间内，所以我们会给1 − 𝛽取值，
大概是从 0.1 到 0.001，应用之前幻灯片中介绍的方法，这是10−1，这是10−3，值得注意的是，在之前的幻灯片里，我们把最小值写在左边，最大值写在右边，但在这里，我们颠倒了大小。
这里，左边的是最大值，右边的是最小值。所以你要做的就是在[−3, −1]里随机均匀的给 r 取值。你设定了1 − 𝛽 = 10的𝑟，所以𝛽 = 1 − 10的𝑟，然后这就变成了在特定的选择范围内超参数随机取值。
希望用这种方式得到想要的结果，你在 0.9 到 0.99 区间探究的资源，和在 0.99 到 0.999 区间探究的一样多。

为什么用线性轴取值不是个好办法，这是因为当𝛽 接近 1 时，所得结果的灵敏度会变化，即使𝛽有微小的变化。所以𝛽 在 0.9 到 0.9005 之间取值，无关紧要，你的结果几乎不会变化。
但𝛽值如果在 0.999 到 0.9995 之间，这会对你的算法产生巨大影响，对吧？在这两种情况下，是根据大概 10 个值取平均。但这里，它是指数的加权平均值，基于 1000 个值，现在
是 2000 个值，因为这个公式 1/1−𝛽，当𝛽接近 1 时，𝛽就会对细微的变化变得很敏感。所以整个取值过程中，你需要更加密集地取值，在𝛽 接近 1 的区间内，或者说，当1 − 𝛽 接近于 0
时，这样，你就可以更加有效的分布取样点，更有效率的探究可能的结果。

3.3 超参数调试实践：Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）
建议：因为某种原因而导致的学习性能下降，需要重新测试或评估你的超参数，至少每隔几个月一次，以确保你对数值依然很满意。

如何搜索超参数的问题，我见过大概两种重要的思想流派或人们通常采用的两种重要但不同的方式。

（1）一种是你照看一个模型，通常是有庞大的数据组，但没有许多计算资源或足够的 CPU 和GPU 的前提下，基本而言，你只可以一次负担起试验一个模型或一小批模型，在这种情况下，
即使当它在试验时，你也可以逐渐改良。比如，第 0 天，你将随机参数初始化，然后开始试验，然后你逐渐观察自己的学习曲线，也许是损失函数 J，或者数据设置误差或其它的东西，
在第 1 天内逐渐减少，那这一天末的时候，你可能会说，看，它学习得真不错。我试着增加一点学习速率，看看它会怎样，也许结果证明它做得更好，那是你第二天的表现。两天后，
你会说，它依旧做得不错，也许我现在可以填充下 Momentum 或减少变量。然后进入第三天，每天，你都会观察它，不断调整你的参数。也许有一天，你会发现你的学习率太大了，
所以你可能又回归之前的模型，像这样，但你可以说是在每天花时间照看此模型，即使是它在许多天或许多星期的试验过程中。所以这是一个人们照料一个模型的方法，观察它的表现，
耐心地调试学习率，但那通常是因为你没有足够的计算能力，不能在同一时间试验大量模型时才采取的办法。

另一种方法则是同时试验多种模型，你设置了一些超参数，尽管让它自己运行，或者是一天甚至多天，然后你会获得像这样的学习曲线，这可以是损失函数 J 或实验误差或损失或数据误差的损失，
但都是你曲线轨迹的度量。同时你可以开始一个有着不同超参数设定的不同模型，所以，你的第二个模型会生成一个不同的学习曲线。与此同时，你可以试验第三种模型，其可能产生一条像这样的学习曲线，
也许这条有所偏离。或者你可以同时平行试验许多不同的模型，橙色的线就是不同的模型。用这种方式你可以试验许多不同的参数设定，然后只是最后快速选择工作效果最好的那个。

所以这两种方式的选择，是由你拥有的计算资源决定的，如果你拥有足够的计算机去平行试验许多模型，那绝对采用鱼子酱方式，尝试许多不同的超参数，看效果怎么样。但在一
些应用领域，比如在线广告设置和计算机视觉应用领域，那里的数据太多了，你需要试验大量的模型，所以同时试验大量的模型是很困难的，它的确是依赖于应用的过程。

3.4 归一化网络的激活函数（Normalizing activations in a network）
在深度学习兴起后，最重要的一个思想是它的一种算法，叫做 Batch 归一化，由 Sergey loffe和Christian Szegedy 两位研究者创造。Batch归一化会使你的参数搜索问题变得很容易，
使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会是你的训练更加容易，甚至是深层网络。

回顾：logistic 回归时，归一化输入特征可以加快学习过程。
所有的输入特征计算平均值，然后对每个特征值减去平均值，做到零均值。
对每个特征值计算方差σ²，对每个特征值除以方差，得到方差为1的输入特征。

对任何一个隐藏层而言，我们能否归一化𝑎值，在此例中，比如说𝑎[2]的值，但可以是任何隐藏层的，以更快的速度训练𝑤[3]，𝑏[3]，因为𝑎[2]是下一层的输入值，所以就会影响𝑤[3]，𝑏[3]的训练。
简单来说，这就是 Batch 归一化的作用。尽管严格来说，我们真正归一化的不是𝑎[2]，而是𝑧[2]，深度学习文献中有一些争论，关于在激活函数之前是否应该将值𝑧[2]归一化，
或是否应该在应用激活函数𝑎[2]后再规范值。实践中，经常做的是归一化𝑧[2]，所以这就是我介绍的版本，我推荐其为默认选择，那下面就是 Batch 归一化的使用方法。

在神经网络中，已知一些中间值，假设你有一些隐藏单元值，从𝑧(1)到𝑧(𝑚)，这些来源于隐藏层，所以这样写会更准确，即𝑧[𝑙](𝑖)为隐藏层，𝑖从 1 到𝑚，但这样书写，我要省略𝑙及
方括号，以便简化这一行的符号。所以已知这些值，如下，你要计算平均值，强调一下，所有这些都是针对𝑙层，但我省略𝑙及方括号，然后用正如你常用的那个公式计算方差，接着，
你会取每个𝑧(𝑖)值，使其规范化，方法如下，减去均值再除以标准偏差，为了使数值稳定，通常将𝜀作为分母，以防𝜎 = 0的情况。

所以现在我们已把这些𝑧值标准化，化为含平均值 0 和标准单位方差，所以𝑧的每一个分量都含有平均值 0 和方差 1，但我们不想让隐藏单元总是含有平均值 0 和方差 1，也许隐藏
单元有了不同的分布会有意义，所以我们所要做的就是计算，我们称之为𝑧̃(𝑖)，𝑧̃(𝑖) = 𝛾 * 𝑧norm(𝑖) + 𝛽，这里𝛾和𝛽是你模型的学习参数，所以我们使用梯度下降或一些其它类似梯度下降的算法，
比如 Momentum 或者 Nesterov，Adam，你会更新𝛾和𝛽，正如更新神经网络的权重一样。

请注意𝛾和𝛽的作用是，你可以随意设置𝑧̃(𝑖)的平均值，事实上，如果𝛾 = 根号下(𝜎2 + 𝜀)，如果𝛾等于这个分母项（𝑧norm(𝑖) = [𝑧(𝑖)−𝜇] / 根号下(𝜎2+𝜀))中的分母，𝛽等于𝜇，
这里的这个值是𝑧norm(𝑖) = [𝑧(𝑖)−𝜇] / 根号下(𝜎2+𝜀) 中的𝜇，那么𝛾 * 𝑧norm(𝑖) + 𝛽的作用在于，它会精确转化这个方程，如果这些成立（𝛾 = 根号下(𝜎2 + 𝜀), 𝛽 = 𝜇），那么𝑧̃(𝑖) = 𝑧(𝑖)。

通过对𝛾和𝛽合理设定，规范化过程，即这四个等式，从根本来说，只是计算恒等函数，通过赋予𝛾和𝛽其它值，可以使你构造含其它平均值和方差的隐藏单元值。

在不需要样本在过程中全部均一化时就无需使用batch归一化了。比如，如果你有 sigmoid 激活函数，你不想让你的值总是全部集中在这里，你想使它们
有更大的方差，或不是 0 的平均值，以便更好的利用非线性的 sigmoid 函数，而不是使所有的值都集中于这个线性版本中，这就是为什么有了𝛾和𝛽两个参数后，你可以确保所有的𝑧(𝑖)
值可以是你想赋予的任意值，或者它的作用是保证隐藏的单元已使均值和方差标准化。那里，均值和方差由两参数控制，即𝛾和𝛽，学习算法可以设置为任何值，所以它真正的作用是，使
隐藏单元值的均值和方差标准化，即𝑧(𝑖)有固定的均值和方差，均值和方差可以是 0 和 1，也可以是其它值，它是由𝛾和𝛽两参数控制的。

3.5 将 Batch Norm 拟合进神经网络（Fitting Batch Norm into a neural network）























