3.1 调试处理（Tuning process）
关于训练深度最难的事情之一是你要处理的参数的数量，从学习速率𝑎到 Momentum（动量梯度下降法）的参数𝛽。如果使用 Momentum 或 Adam 优化算法的参数，𝛽1，𝛽2和𝜀，
也许你还得选择层数，也许你还得选择不同层中隐藏单元的数量，也许你还想使用学习率衰减。所以，你使用的不是单一的学习率𝑎。接着，当然你可能还需要选择 mini-batch 的大小。

最重要的超参数：a 学习率

除了𝑎，还有一些参数需要调试，例如 Momentum 参数𝛽，0.9 就是个很好的默认值。我还会调试 mini-batch 的大小，以确保最优算法运行有效。我还会经常调试隐藏单元，我用橙
色圈住的这些，这三个是我觉得其次比较重要的，相对于𝑎而言。重要性排第三位的是其他因素，层数有时会产生很大的影响，学习率衰减也是如此。当应用 Adam 算法时，事实上，
我从不调试𝛽1，𝛽2和𝜀，我总是选定其分别为 0.9，0.999 和10的−8，如果你想的话也可以调试。

Andrew NG认为的超参数的调整重要性：
a >> β = hidden units = mini-batch size > layers = learning rate decay >> β1（默认0.9） = β2（默认0.999） = ε（默认10的-8次方）

方法一：在超参数比较少的情况下，可以使用随机取样本点的方法尝试超参数的学习效果
现在，如果你尝试调整一些超参数，该如何选择调试值呢？在早一代的机器学习算法中，如果你有两个超参数，这里我会称之为超参 1，超参 2，常见的做法是在网格中取样点，像
这样，然后系统的研究这些数值。这里我放置的是 5×5 的网格，实践证明，网格可以是 5×5，也可多可少，但对于这个例子，你可以尝试这所有的 25 个点，然后选择哪个参数效果最好。
当参数的数量相对较少时，这个方法很实用。  

推荐你采用下面的做法，随机选择点，所以你可以选择同等数量的点。25 个点，接着，用这些随机取的点试验超参数的效果。之所以这么做是因为，对于你要解决的问题而言，
你很难提前知道哪个超参数最重要，正如你之前看到的，一些超参数的确要比其它的更重要。
举个例子，假设超参数 1 是𝑎（学习速率），取一个极端的例子，假设超参数 2 是 Adam算法中，分母中的𝜀。在这种情况下，𝑎的取值很重要，而𝜀取值则无关紧要。如果你在网格
中取点，接着，你试验了𝑎的 5 个取值，那你会发现，无论𝜀取何值，结果基本上都是一样的。所以，你知道共有 25 种模型，但进行试验的𝑎值只有 5 个，我认为这是很重要的。
对比而言，如果你随机取值，你会试验 25 个独立的𝑎，似乎你更有可能发现效果做好的那个。

实践中，你搜索的超参数可能不止两个。假如，你有三个超参数，这时你搜索的不是一个方格，而是一个立方体，超参数 3 代表第三维，接着，在
三维立方体中取值，你会试验大量的更多的值，三个超参数中每个都是。

实践中，你搜索的可能不止三个超参数有时很难预知，哪个是最重要的超参数，对于你的具体应用而言，随机取值而不是网格取值表明，你探究了更多重要超参数的潜在值，无论结果是什么。

给超参数取值时，另一个惯例是采用由粗糙到精细的策略。比如在二维的那个例子中，你进行了取值，也许你会发现效果最好的某个点，也许这个点周围的其他一些点效果也很好，
那在接下来要做的是放大这块小区域（小蓝色方框内），然后在其中更密集得取值或随机取值，聚集更多的资源，在这个蓝色的方格中搜索，如果你怀疑这些超参数在这个区域的最优结果，
那在整个的方格中进行粗略搜索后，你会知道接下来应该聚焦到更小的方格中。在更小的方格中，你可以更密集得取点。所以这种从粗到细的搜索也经常使用。

通过试验超参数的不同取值，你可以选择对训练集目标而言的最优值，或对于开发集而言的最优值，或在超参搜索过程中你最想优化的东西。

3.2 为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）
随机取值可以提升你的搜索效率。但随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺，用于探究这些超参数，这很重要。

你要选取隐藏单元的数量𝑛[𝑙]，假设，你选取的取值范围是从 50 到 100 中某点，这种情况下，看到这条从 50-100 的数轴，你可以随机在其取点，这是一个搜索特定超参数的
很直观的方式。或者，如果你要选取神经网络的层数，我们称之为字母𝐿，你也许会选择层数为 2 到 4 中的某个值，接着顺着 2，3，4 随机均匀取样才比较合理，你还可以应用网格搜
索，你会觉得 2，3，4，这三个数值是合理的，这是在几个在你考虑范围内随机均匀取值的例子，这些取值还蛮合理的，但对某些超参数而言不适用。

假设你在搜索超参数𝑎（学习速率），假设你怀疑其值最小是 0.0001 或最大是 1。如果 你画一条从 0.0001 到 1 的数轴，沿其随机均匀取值，那 90%的数值将会落在0.1 到 1 之间，
结果就是，在 0.1 到 1 之间，应用了 90%的资源，而在 0.0001 到 0.1 之间，只有 10%的搜索资源，这看上去不太对。反而，用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，
分别依次取0.0001，0.001，0.01，0.1，1，在对数轴上均匀随机取点，这样，在 0.0001 到 0.001 之间，就会有更多的搜索资源可用，还有在 0.001 到 0.01 之间等等。

在 Python 中，你可以这样做，使 r=-4*np.random.rand()，然后𝑎随机取值，𝑎 = 10𝑟，所以，第一行可以得出𝑟 ∈ [4,0]，那么𝑎 ∈ [10的−4, 100]，所以最左边的数字是10的−4，最右边是100。
更常见的情况是，如果你在10的𝑎和10的𝑏之间取值，在此例中，这是10的𝑎（0.0001），你可以通过0.0001算出𝑎的值，即-4，在右边的值是10𝑏，你可以算出𝑏的值1，即 0。你要做的就
是在[𝑎, 𝑏]区间随机均匀地给𝑟取值，这个例子中𝑟 ∈ [−4,0]，然后你可以设置𝑎的值，基于随机取样的超参数𝑎 = 10的𝑟。

所以总结一下，在对数坐标下取值，取最小值的对数就得到𝑎的值，取最大值的对数就得到𝑏值，所以现在你在对数轴上的10的𝑎到10的𝑏区间取值，在𝑎，𝑏间随意均匀的选取𝑟值，
将超参数设置为10的𝑟，这就是在对数轴上取值的过程。所以总结一下，在对数坐标下取值，取最小值的对数就得到𝑎的值，取最大值的对数就得到𝑏值，所以现在你在对数轴上的10的𝑎到10的𝑏区间取值，
在𝑎，𝑏间随意均匀的选取𝑟值，将超参数设置为10的𝑟，这就是在对数轴上取值的过程。

最后，另一个棘手的例子是给𝛽 取值，用于计算指数的加权平均值。假设你认为𝛽是 0.9到 0.999 之间的某个值，也许这就是你想搜索的范围。记住这一点，当计算指数的加权平均
值时，取 0.9 就像在 10 个值中计算平均值，有点类似于计算 10 天的温度平均值，而取 0.999就是在 1000 个值中取平均。所以和上张幻灯片上的内容类似，如果你想在 0.9 到 0.999 区间搜索，
那就不能用线性轴取值，对吧？不要随机均匀在此区间取值，所以考虑这个问题最好的方法就是，我们要探究的是1 − 𝛽，此值在 0.1 到 0.001 区间内，所以我们会给1 − 𝛽取值，
大概是从 0.1 到 0.001，应用之前幻灯片中介绍的方法，这是10−1，这是10−3，值得注意的是，在之前的幻灯片里，我们把最小值写在左边，最大值写在右边，但在这里，我们颠倒了大小。
这里，左边的是最大值，右边的是最小值。所以你要做的就是在[−3, −1]里随机均匀的给 r 取值。你设定了1 − 𝛽 = 10的𝑟，所以𝛽 = 1 − 10的𝑟，然后这就变成了在特定的选择范围内超参数随机取值。
希望用这种方式得到想要的结果，你在 0.9 到 0.99 区间探究的资源，和在 0.99 到 0.999 区间探究的一样多。

为什么用线性轴取值不是个好办法，这是因为当𝛽 接近 1 时，所得结果的灵敏度会变化，即使𝛽有微小的变化。所以𝛽 在 0.9 到 0.9005 之间取值，无关紧要，你的结果几乎不会变化。
但𝛽值如果在 0.999 到 0.9995 之间，这会对你的算法产生巨大影响，对吧？在这两种情况下，是根据大概 10 个值取平均。但这里，它是指数的加权平均值，基于 1000 个值，现在
是 2000 个值，因为这个公式 1/1−𝛽，当𝛽接近 1 时，𝛽就会对细微的变化变得很敏感。所以整个取值过程中，你需要更加密集地取值，在𝛽 接近 1 的区间内，或者说，当1 − 𝛽 接近于 0
时，这样，你就可以更加有效的分布取样点，更有效率的探究可能的结果。

3.3 超参数调试实践：Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）
建议：因为某种原因而导致的学习性能下降，需要重新测试或评估你的超参数，至少每隔几个月一次，以确保你对数值依然很满意。

如何搜索超参数的问题，我见过大概两种重要的思想流派或人们通常采用的两种重要但不同的方式。

（1）一种是你照看一个模型，通常是有庞大的数据组，但没有许多计算资源或足够的 CPU 和GPU 的前提下，基本而言，你只可以一次负担起试验一个模型或一小批模型，在这种情况下，
即使当它在试验时，你也可以逐渐改良。比如，第 0 天，你将随机参数初始化，然后开始试验，然后你逐渐观察自己的学习曲线，也许是损失函数 J，或者数据设置误差或其它的东西，
在第 1 天内逐渐减少，那这一天末的时候，你可能会说，看，它学习得真不错。我试着增加一点学习速率，看看它会怎样，也许结果证明它做得更好，那是你第二天的表现。两天后，
你会说，它依旧做得不错，也许我现在可以填充下 Momentum 或减少变量。然后进入第三天，每天，你都会观察它，不断调整你的参数。也许有一天，你会发现你的学习率太大了，
所以你可能又回归之前的模型，像这样，但你可以说是在每天花时间照看此模型，即使是它在许多天或许多星期的试验过程中。所以这是一个人们照料一个模型的方法，观察它的表现，
耐心地调试学习率，但那通常是因为你没有足够的计算能力，不能在同一时间试验大量模型时才采取的办法。

另一种方法则是同时试验多种模型，你设置了一些超参数，尽管让它自己运行，或者是一天甚至多天，然后你会获得像这样的学习曲线，这可以是损失函数 J 或实验误差或损失或数据误差的损失，
但都是你曲线轨迹的度量。同时你可以开始一个有着不同超参数设定的不同模型，所以，你的第二个模型会生成一个不同的学习曲线。与此同时，你可以试验第三种模型，其可能产生一条像这样的学习曲线，
也许这条有所偏离。或者你可以同时平行试验许多不同的模型，橙色的线就是不同的模型。用这种方式你可以试验许多不同的参数设定，然后只是最后快速选择工作效果最好的那个。

所以这两种方式的选择，是由你拥有的计算资源决定的，如果你拥有足够的计算机去平行试验许多模型，那绝对采用鱼子酱方式，尝试许多不同的超参数，看效果怎么样。但在一
些应用领域，比如在线广告设置和计算机视觉应用领域，那里的数据太多了，你需要试验大量的模型，所以同时试验大量的模型是很困难的，它的确是依赖于应用的过程。

3.4 归一化网络的激活函数（Normalizing activations in a network）
在深度学习兴起后，最重要的一个思想是它的一种算法，叫做 Batch 归一化，由 Sergey loffe和Christian Szegedy 两位研究者创造。Batch归一化会使你的参数搜索问题变得很容易，
使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会是你的训练更加容易，甚至是深层网络。

回顾：logistic 回归时，归一化输入特征可以加快学习过程。
所有的输入特征计算平均值，然后对每个特征值减去平均值，做到零均值。
对每个特征值计算方差σ²，对每个特征值除以方差，得到方差为1的输入特征。

对任何一个隐藏层而言，我们能否归一化𝑎值，在此例中，比如说𝑎[2]的值，但可以是任何隐藏层的，以更快的速度训练𝑤[3]，𝑏[3]，因为𝑎[2]是下一层的输入值，所以就会影响𝑤[3]，𝑏[3]的训练。
简单来说，这就是 Batch 归一化的作用。尽管严格来说，我们真正归一化的不是𝑎[2]，而是𝑧[2]，深度学习文献中有一些争论，关于在激活函数之前是否应该将值𝑧[2]归一化，
或是否应该在应用激活函数𝑎[2]后再规范值。实践中，经常做的是归一化𝑧[2]，所以这就是我介绍的版本，我推荐其为默认选择，那下面就是 Batch 归一化的使用方法。

在神经网络中，已知一些中间值，假设你有一些隐藏单元值，从𝑧(1)到𝑧(𝑚)，这些来源于隐藏层，所以这样写会更准确，即𝑧[𝑙](𝑖)为隐藏层，𝑖从 1 到𝑚，但这样书写，我要省略𝑙及
方括号，以便简化这一行的符号。所以已知这些值，如下，你要计算平均值，强调一下，所有这些都是针对𝑙层，但我省略𝑙及方括号，然后用正如你常用的那个公式计算方差，接着，
你会取每个𝑧(𝑖)值，使其规范化，方法如下，减去均值再除以标准偏差，为了使数值稳定，通常将𝜀作为分母，以防𝜎 = 0的情况。

所以现在我们已把这些𝑧值标准化，化为含平均值 0 和标准单位方差，所以𝑧的每一个分量都含有平均值 0 和方差 1，但我们不想让隐藏单元总是含有平均值 0 和方差 1，也许隐藏
单元有了不同的分布会有意义，所以我们所要做的就是计算，我们称之为𝑧̃(𝑖)，𝑧̃(𝑖) = 𝛾 * 𝑧norm(𝑖) + 𝛽，这里𝛾和𝛽是你模型的学习参数，所以我们使用梯度下降或一些其它类似梯度下降的算法，
比如 Momentum 或者 Nesterov，Adam，你会更新𝛾和𝛽，正如更新神经网络的权重一样。

请注意𝛾和𝛽的作用是，你可以随意设置𝑧̃(𝑖)的平均值，事实上，如果𝛾 = 根号下(𝜎² + 𝜀)，如果𝛾等于这个分母项（𝑧norm(𝑖) = [𝑧(𝑖)−𝜇] / 根号下(𝜎2+𝜀))中的分母，𝛽等于𝜇，
这里的这个值是𝑧norm(𝑖) = [𝑧(𝑖)−𝜇] / 根号下(𝜎2+𝜀) 中的𝜇，那么𝛾 * 𝑧norm(𝑖) + 𝛽的作用在于，它会精确转化这个方程，如果这些成立（𝛾 = 根号下(𝜎2 + 𝜀), 𝛽 = 𝜇），那么𝑧̃(𝑖) = 𝑧(𝑖)。

通过对𝛾和𝛽合理设定，规范化过程，即这四个等式，从根本来说，只是计算恒等函数，通过赋予𝛾和𝛽其它值，可以使你构造含其它平均值和方差的隐藏单元值。

在不需要样本在过程中全部均一化时就无需使用batch归一化了。比如，如果你有 sigmoid 激活函数，你不想让你的值总是全部集中在这里，你想使它们
有更大的方差，或不是 0 的平均值，以便更好的利用非线性的 sigmoid 函数，而不是使所有的值都集中于这个线性版本中，这就是为什么有了𝛾和𝛽两个参数后，你可以确保所有的𝑧(𝑖)
值可以是你想赋予的任意值，或者它的作用是保证隐藏的单元已使均值和方差标准化。那里，均值和方差由两参数控制，即𝛾和𝛽，学习算法可以设置为任何值，所以它真正的作用是，使
隐藏单元值的均值和方差标准化，即𝑧(𝑖)有固定的均值和方差，均值和方差可以是 0 和 1，也可以是其它值，它是由𝛾和𝛽两参数控制的。

3.5 将 Batch Norm 拟合进神经网络（Fitting Batch Norm into a neural network）
每个单元负责计算两件事。第一，它先计算𝑧，然后应用其到激活函数中再计算𝑎，所以我可以认为，每个圆圈代表着两步的计算过程。同样的，对于下一层而言，那就是𝑧1[2]和𝑎1[2]等。
所以如果你没有应用 Batch 归一化，你会把输入𝑋拟合到第一隐藏层，然后首先计算𝑧[1]，这是由𝑤[1]和𝑏[1]两个参数控制的。接着，通常而言，你会把𝑧[1]拟合到激活函数以计算𝑎[1]。
但 Batch 归一化的做法是将𝑧[1]值进行 Batch 归一化，简称 BN，此过程将由𝛽[1]和𝛾[1]两参数控制，这一操作会给你一个新的规范化的𝑧[1]值（𝑧̃[1]），然后将其输入激活函数中得到𝑎[1]，
即𝑎[1] = 𝑔[1](𝑧̃[𝑙])。

现在，你已在第一层进行了计算，此时 Batch 归一化发生在𝑧的计算和𝑎之间，接下来，你需要应用𝑎[1]值来计算𝑧[2]，此过程是由𝑤[2]和𝑏[2]控制的。与你在第一层所做的类似，你
会将𝑧[2]进行 Batch 归一化，现在我们简称 BN，这是由下一层的 Batch 归一化参数所管制的，即𝛽[2]和𝛾[2]，现在你得到𝑧̃[2]，再通过激活函数计算出𝑎[2]等等。

所以需要强调的是 Batch 归一化是发生在计算𝑧和𝑎之间的。直觉就是，与其应用没有归一化的𝑧值，不如用归一过的𝑧̃，这是第一层（𝑧̃[1]）。第二层同理，与其应用没有规范过的
𝑧[2]值，不如用经过方差和均值归一后的𝑧̃[2]。所以，你网络的参数就会是𝑤[1]，𝑏[1]，𝑤[2]和 𝑏[2]等等，我们将要去掉这些参数。但现在，想象参数𝑤[1]，𝑏[1]到𝑤[𝑙]，𝑏[𝑙]，我们将另一些
参数加入到此新网络中𝛽[1]，𝛽[2]，𝛾[1]，𝛾[2]等等。对于应用 Batch 归一化的每一层而言。需要澄清的是，请注意，这里的这些𝛽（𝛽[1]，𝛽[2]等等）和超参数𝛽没有任何关系，下一张幻
灯片中会解释原因，后者是用于 Momentum 或计算各个指数的加权平均值。Adam 论文的作者，在论文里用𝛽代表超参数。Batch 归一化论文的作者，则使用𝛽代表此参数（𝛽[1]，𝛽[2]
等等），但这是两个完全不同的𝛽。我在两种情况下都决定使用𝛽，以便你阅读那些原创的论文，但 Batch 归一化学习参数𝛽[1]，𝛽[2]等等和用于 Momentum、Adam、RMSprop 算法中的𝛽不同。

所以现在，这是你算法的新参数，接下来你可以使用想用的任何一种优化算法，比如使用梯度下降法来执行它。举个例子，对于给定层，你会计算𝑑𝛽[𝑙]，接着更新参数𝛽为𝛽[𝑙] = 𝛽[𝑙] − 𝛼𝑑𝛽[𝑙]。你也可
以使用 Adam 或 RMSprop 或 Momentum，以更新参数𝛽和𝛾，并不是只应用梯度下降法。即使在之前的视频中，我已经解释过 Batch 归一化是怎么操作的，计算均值和方差，减
去均值，再除以方差，如果它们使用的是深度学习编程框架，通常你不必自己把 Batch 归一化步骤应用于 Batch 归一化层。因此，探究框架，可写成一行代码，比如说，在 TensorFlow
框架中，你可以用这个函数（tf.nn.batch_normalization）来实现 Batch 归一化，我们稍后讲解，但实践中，你不必自己操作所有这些具体的细节，但知道它是如何作用的，你可
以更好的理解代码的作用。但在深度学习框架中，Batch 归一化的过程，经常是类似一行代码的东西。

实践中，Batch 归一化通常和训练集的 mini-batch 一起使用。你应用 Batch 归一化的方式就是，你用第一个 mini-batch(𝑋{1})，然后计算𝑧[1]，这和上张幻灯片上我们所做的一样，
应用参数𝑤[1]和𝑏[1]，使用这个 mini-batch(𝑋{1})。接着，继续第二个 mini-batch(𝑋{2})，接着Batch 归一化会减去均值，除以标准差，由𝛽[1]和𝛾[1]重新缩放，这样就得到了𝑧̃[1]，而所有的
这些都是在第一个 mini-batch 的基础上，你再应用激活函数得到𝑎[1]。然后用𝑤[2]和𝑏[2]计算𝑧[2]，等等，所以你做的这一切都是为了在第一个 mini-batch(𝑋{1})上进行一步梯度下降法。
类似的工作，你会在第二个 mini-batch（𝑋{2}）上计算𝑧[1]，然后用 Batch 归一化来计算𝑧̃[1]，所以 Batch 归一化的此步中，你用第二个 mini-batch（𝑋{2}）中的数据使𝑧̃[1]归一化，这
里的 Batch 归一化步骤也是如此，让我们来看看在第二个 mini-batch（𝑋{2}）中的例子，在mini-batch 上计算𝑧[1]的均值和方差，重新缩放的𝛽和𝛾得到𝑧[1]，等等。

现在，我想澄清此参数的一个细节。先前我说过每层的参数是𝑤[𝑙]和𝑏[𝑙]，还有𝛽[𝑙]和𝛾[𝑙]，请注意计算𝑧的方式如下，𝑧[𝑙] = 𝑤[𝑙]𝑎[𝑙−1] + 𝑏[𝑙]，但 Batch 归一化做的是，它要看这个 mini-batch，
先将𝑧[𝑙]归一化，结果为均值 0 和标准方差，再由𝛽和𝛾重缩放，但这意味着，无论𝑏[𝑙]的值是多少，都是要被减去的，因为在 Batch 归一化的过程中，你要计算𝑧[𝑙]的均值，再减去平均值，
在此例中的 mini-batch 中增加任何常数，数值都不会改变，因为加上的任何常数都将会被均值减去所抵消。

操作：如果在使用 Batch 归一化，其实你可以消除这个参数（𝑏[𝑙]），或者你也可以，暂时把它设置为 0，那么，参数变成𝑧[𝑙] = 𝑤[𝑙]𝑎[𝑙−1]，然后你计算归一化的𝑧[𝑙]，
𝑧̃[𝑙] = 𝛾[𝑙]𝑧[𝑙] + 𝛽[𝑙]，你最后会用参数𝛽[𝑙]，以便决定𝑧̃[𝑙]的取值，这就是原因。

所以总结一下，因为 Batch 归一化超过了此层𝑧[𝑙]的均值，𝑏[𝑙]这个参数没有意义，所以，你必须去掉它，由𝛽[𝑙]代替，这是个控制参数，会影响转移或偏置条件。
最后，请记住𝑧[𝑙]的维数，因为在这个例子中，维数会是(𝑛[𝑙], 1)，𝑏[𝑙]的尺寸为(𝑛[𝑙], 1)，如果是 l 层隐藏单元的数量，那𝛽[𝑙]和𝛾[𝑙]的维度也是(𝑛[𝑙], 1)，因为这是你隐藏层的数量，你
有𝑛[𝑙]隐藏单元，所以𝛽[𝑙]和𝛾[𝑙]用来将每个隐藏层的均值和方差缩放为网络想要的值。

让我们总结一下关于如何用 Batch 归一化来应用梯度下降法，假设你在使用 mini-batch梯度下降法，你运行𝑡 = 1到 batch 数量的 for 循环，你会在 mini-batch 𝑋{𝑡}上应用正向 prop，
每个隐藏层都应用正向 prop，用 Batch 归一化代替𝑧[𝑙]为𝑧̃[𝑙]。接下来，它确保在这个 mini-batch 中，𝑧值有归一化的均值和方差，归一化均值和方差后是𝑧̃[𝑙]，然后，你用反向 prop 计 算𝑑𝑤[𝑙]和𝑑𝑏[𝑙]，
及所有l层所有的参数，𝑑𝛽[𝑙]和𝑑𝛾[𝑙]。尽管严格来说，因为你要去掉𝑏，这部分其实已经去掉了。最后，你更新这些参数：𝑤[𝑙] = 𝑤[𝑙] − αd𝑤[𝑙]，和以前一样，𝛽[𝑙] = 𝛽[𝑙] − 𝛼𝑑𝛽[𝑙]，
对于𝛾也是如此𝛾[𝑙] = 𝛾[𝑙] − 𝛼𝑑𝛾[𝑙]。

如果你已将梯度计算如下，你就可以使用梯度下降法了，这就是我写到这里的，但也适用于有 Momentum、RMSprop、Adam 的梯度下降法。与其使用梯度下降法更新 mini-batch，
你可以使用这些其它算法来更新，我们在之前几个星期中的视频中讨论过的，也可以应用其它的一些优化算法来更新由 Batch 归一化添加到算法中的𝛽 和𝛾 参数

3.6 Batch Norm 为什么奏效？（Why does Batch Norm work?）
Batch Norm的直接作用是对隐藏层进行归一化，从而直接对隐藏单元进行作用。
其次，Batch 归一化有效的第二个原因是，它可以使权重比你的网络更滞后或更深层，比如，第 10 层的权重更能经受得住变化，相比于神经网络中前层的权重。
比如 logistic 回归或是一个神经网络，也许是个浅层网络，像这个回归函数。或一个深层网络，建立在我们著名的猫脸识别检测上，但假设你已经在所有黑猫的图像上训练了数据集，
如果现在你要把此网络应用于有色猫，这种情况下，正面的例子不只是左边的黑猫，还有右边其它颜色的猫，那么你的 cosfa 可能适用的不会很好。

协变量(Covariate)：影响研究对象的因素，只是在分析的过程中，通过协方差分析，消除其对研究结果产生的影响
如果你已经学习了𝑥到𝑦 的映射，如果𝑥的分布改变了，那么你可能需要重新训练你的学习算法。这种做法同样适用于，如果真实函数由𝑥到𝑦 映射保持不变，正如此例中，因为真实
函数是此图片是否是一只猫，训练你的函数的需要变得更加迫切，如果真实函数也改变，情况就更糟了。
比如对两组数据进行拟合，如果两组数据都运行的不错，但我们不希望神经网路发现我们的决策边界，如果只学习单一一侧的话。（这里的理解应该是对于某一小片数据不应该让网络训练出
非常明显的边界，如果后面的数据方差比较大，那么产生的拟合结果就会变差，而Batch正则化就是削弱后面隐藏单元对于各种变化的响应程度）

Batch 归一化做的，是它减少了这些隐藏值分布变化的数量。如果是绘制这些隐藏的单元值的分布，也许这是重整值𝑧，这其实是𝑧1[2]，𝑧2[2]，我要绘制两个值而不是四个值，以便
我们设想为 2D，Batch 归一化讲的是𝑧1[2]，𝑧2[2]的值可以改变，它们的确会改变，当神经网络在之前层中更新参数，Batch 归一化可以确保无论其怎样变化𝑧1[2]，𝑧2[2]的均值和方差保持不
变，所以即使𝑧1[2]，𝑧2[2]的值改变，至少他们的均值和方差也会是均值 0，方差 1，或不一定必须是均值 0，方差 1，而是由𝛽[2]和𝛾[2]决定的值。如果神经网络选择的话，可强制其为均
值 0，方差 1，或其他任何均值和方差。但它做的是，它限制了在前层的参数更新，会影响数值分布的程度，第三层看到的这种情况，因此得到学习。

总结：对于Batch归一化的作用，简单来说是其归一化了每一层的输入，使其保持均值0，方差1或者由γ[l],β[l]来决定输入的均值和方差。深层次的原因在于，在某一层l之前仍存在数个
隐藏单元，这些隐藏单元对于整个网络都有影响。首先，每个隐藏单元（或者隐藏层）都完成了相应的学习任务和参数更新，对于后一隐藏层而言，这样对于输入的改变很有可能会对学习效果产生
不可预计的影响，例如对于某种生物的边缘特征变化或者对于颜色变化这种区分度比较大的数据来说，前面隐藏层产生的结果如果直接应用于后一隐藏层，可能会减弱学习的效果。
Batch 归一化减少了输入值改变的问题，它的确使这些值变得更稳定，神经网络的之后层就会有更坚实的基础。即使使输入分布改变了一些，它会改变得更少。它做的是当前层保持学习，当改变时，
迫使后层适应的程度减小了，它减弱了前层参数的作用与后层参数的作用之间的联系，它使得网络每层都可以自己学习，稍稍独立于其它层，这有助于加速整个网络的学习。

重点是 Batch 归一化的意思是，尤其从神经网络后层之一的角度而言，前层不会左右移动的那么多，因为它们被同样的均值和方差所限制，所以，这会使得后层的学习工作变得更容易些。
Batch 归一化还有一个作用，它有轻微的正则化效果，Batch 归一化中非直观的一件事是，每个 mini-batch，我会说 mini-batch 𝑋{𝑡}的值为𝑧[𝑡]，𝑧[𝑙]，在 mini-batch 计算中，由均值
和方差缩放的，因为在 mini-batch 上计算的均值和方差，而不是在整个数据集上，均值和方差有一些小的噪声，因为它只在你的 mini-batch 上计算，比如 64 或 128 或 256 或更大的训
练例子。因为均值和方差有一点小噪音，因为它只是由一小部分数据估计得出的。缩放过程从𝑧[𝑙]到𝑧̃[𝑙]，过程也有一些噪音，因为它是用有些噪音的均值和方差计算得出的。

和 dropout 相似，它往每个隐藏层的激活值上增加了噪音，dropout 有增加噪音的方式，它使一个隐藏的单元，以一定的概率乘以 0，以一定的概率乘以 1，所以你的 dropout
含几重噪音，因为它乘以 0 或 1。对比而言，Batch 归一化含几重噪音，因为标准偏差的缩放和减去均值带来的额外噪音。这里的均值和标准差的估计值也是有噪音的，所以类似于 dropout，
Batch 归一化有轻微的正则化效果，因为给隐藏单元添加了噪音，这迫使后部单元不过分依赖任何一个隐藏单元，类似于 dropout，它给隐藏层增加了噪音，因此有轻微的正则化效果。
因为添加的噪音很微小，所以并不是巨大的正则化效果，你可以将 Batch 归一化和 dropout 一起使用，如果你想得到 dropout 更强大的正则化效果。

也许另一个轻微非直观的效果是，如果你应用了较大的 mini-batch，对，比如说，你用了 512 而不是 64，通过应用较大的 min-batch，你减少了噪音，因此减少了正则化效果，这
是 dropout 的一个奇怪的性质，就是应用较大的 mini-batch 可以减少正则化效果。说到这儿，我会把 Batch 归一化当成一种正则化，这确实不是其目的，但有时它会对你
的算法有额外的期望效应或非期望效应。但是不要把 Batch 归一化当作正则化，把它当作将你归一化隐藏单元激活值并加速学习的方式，我认为正则化几乎是一个意想不到的副作用。
所以希望这能让你更理解 Batch 归一化的工作，在我们结束 Batch 归一化的讨论之前，我想确保你还知道一个细节。Batch 归一化一次只能处理一个 mini-batch 数据，
它在 mini-batch 上计算均值和方差。所以测试时，你试图做出预测，试着评估神经网络，你也许没有mini-batch 的例子，你也许一次只能进行一个简单的例子，所以测试时，你需要做一些不同
的东西以确保你的预测有意义。

3.7 测试时的 Batch Norm（Batch Norm at test time）
Batch 归一化将你的数据以 mini-batch 的形式逐一处理，但在测试时，你可能需要对每个样本逐一处理。

用 m 来表示这个 mini-batch 中的样本数量，而不是整个训练集。然后计算方差，再算𝑧norm(𝑖) ，即用均值和标准差来调整，加上𝜀是为了数值稳定性。𝑧̃是用𝛾和𝛽再次调整𝑧norm得
到的。请注意用于调节计算的𝜇和𝜎2是在整个 mini-batch 上进行计算，但是在测试时，你可能不能将一个 mini-batch 中的 6428 或 2056 个样本同时处理，
因此你需要用其它方式来得到𝜇 和𝜎2，而且如果你只有一个样本，一个样本的均值和方差没有意义。那么实际上，为了将你的神经网络运用于测试，就需要单独估算𝜇和𝜎2，
在典型的 Batch 归一化运用中，你需要用一个指数加权平均来估算，这个平均数涵盖了所有 mini-batch，接下来我会具体解释。

重温Batch Norm的过程：
（1）计算某个mini-batch均值
（2）计算某个mini-batch方差
（3）计算归一化后的𝑧norm(𝑖)（注意分母上根号中加上的极小值epsilon）
（4）计算重新设置均值和方差之后的𝑧̃(𝑖)（均值和方差由γ和β确定

我们选择𝑙层，假设我们有 mini-batch，𝑋[1]，𝑋[2]，𝑋[3]……以及对应的𝑦值等等，那么在为𝑙层训练𝑋{1}时，你就得到了𝜇[𝑙]，我还是把它写做第一个 mini-batch 和这一层的𝜇吧，（𝜇[𝑙] → 𝜇{1}[𝑙]）。
当你训练第二个 mini-batch，在这一层和这个 mini-batch 中，你就会得到第二个𝜇 （𝜇{2}[𝑙]）值。然后在这一隐藏层的第三个 mini-batch，你得到了第三个𝜇（𝜇{3}[𝑙]）值。正如
我们之前用的指数加权平均来计算𝜃1，𝜃2，𝜃3的均值，当时是试着计算当前气温的指数加权平均，你会这样来追踪你看到的这个均值向量的最新平均值，于是这个指数加权平均就成了
你对这一隐藏层的𝑧均值的估值。同样的，你可以用指数加权平均来追踪你在这一层的第一个 mini-batch 中所见的𝜎2的值，以及第二个 mini-batch 中所见的𝜎2的值等等。因此在用不
同的 mini-batch 训练神经网络的同时，能够得到你所查看的每一层的𝜇和𝜎2的平均数的实时数值。

最后在测试时，对应这个等式（𝑧norm(𝑖) = (𝑧(𝑖) −𝜇 ) /√(𝜎2 + 𝜀)），你只需要用你的𝑧值来计算𝑧norm(𝑖) ，用𝜇和𝜎2的指数加权平均，用你手头的最新数值来做调整，然后你可以用左边我们刚算出来的
𝑧norm和你在神经网络训练过程中得到的𝛽和𝛾参数来计算你那个测试样本的𝑧̃值。总结一下就是，在训练时，𝜇和𝜎2是在整个 mini-batch 上计算出来的包含了像是 64 或
128 或其它一定数量的样本，但在测试时，你可能需要逐一处理样本，方法是根据你的训练集估算𝜇和𝜎2，估算的方式有很多种，理论上你可以在最终的网络中运行整个训练集来得到
𝜇和𝜎2，但在实际操作中，我们通常运用指数加权平均来追踪在训练过程中你看到的𝜇和𝜎2的值。还可以用指数加权平均，有时也叫做流动平均来粗略估算𝜇和𝜎2，然后在测试中使用
𝜇和𝜎2的值来进行你所需要的隐藏单元𝑧值的调整。在实践中，不管你用什么方式估算𝜇和𝜎2，这套过程都是比较稳健的，因此我不太会担心你具体的操作方式，而且如果你使用的是某种
深度学习框架，通常会有默认的估算𝜇和𝜎2的方式，应该一样会起到比较好的效果。但在实践中，任何合理的估算你的隐藏单元𝑧值的均值和方差的方式，在测试中应该都会有效。

3.8 Softmax 回归（Softmax regression）
对多分类问题使用softmax回归：
到目前为止，我们讲到过的分类的例子都使用了二分分类，这种分类只有两种可能的标记 0 或 1，这是一只猫或者不是一只猫，如果我们有多种可能的类型的话呢？有一种 logistic
回归的一般形式，叫做 Softmax 回归，能让你在试图识别某一分类时做出预测，或者说是多种分类中的一个，不只是识别两个分类，我们来一起看一下。

假设你不单需要识别猫，而是想识别猫，狗和小鸡，我把猫加做类 1，狗为类 2，小鸡是类 3，如果不属于以上任何一类，就分到“其它”或者说“以上均不符合”这一类，我把它叫
做类 0。这里显示的图片及其对应的分类就是一个例子，这幅图片上是一只小鸡，所以是类3，猫是类 1，狗是类 2，我猜这是一只考拉，所以以上均不符合，那就是类 0，下一个类 3，
以此类推。我们将会用符号表示，我会用大写的𝐶来表示你的输入会被分入的类别总个数，在这个例子中，我们有 4 种可能的类别，包括“其它”或“以上均不符合”这一类。当有 4 个分
类时，指示类别的数字，就是从 0 到𝐶 − 1，换句话说就是 0、1、2、3

在这个例子中，我们将建立一个神经网络，其输出层有 4 个，或者说𝐶个输出单元，因此𝑛，即输出层也就是𝐿层的单元数量，等于 4，或者一般而言等于𝐶。我们想要输出层单元
的数字告诉我们这 4 种类型中每个的概率有多大，所以这里的第一个节点(最后输出的第 1个方格+圆圈)输出的应该是或者说我们希望它输出“其它”类的概率。在输入𝑋的情况下，这
个(最后输出的第 2 个方格+圆圈)会输出猫的概率。在输入𝑋的情况下，这个会输出狗的概率(最后输出的第 3 个方格+圆圈)。在输入𝑋的情况下，输出小鸡的概率（最后输出的第 4 个方
格+圆圈），我把小鸡缩写为 bc（baby chick）。因此这里的𝑦^将是一个4 × 1维向量，因为它必须输出四个数字，给你这四种概率，因为它们加起来应该等于 1，输出中的四个数字加起
来应该等于 1。
让你的网络做到这一点的标准模型要用到 Softmax 层，以及输出层来生成输出，

softmax函数的应用场景与应用多二分类的区别：
现在我们来看一个计算视觉领域的例子，你的任务是将图像分到三个不同类别中。
(i) 假设这三个类别分别是：室内场景、户外城区场景、户外荒野场景。你会使用sofmax回归还是 3个logistic 回归分类器呢？ 
(ii) 现在假设这三个类别分别是室内场景、黑白图片、包含人物的图片，你又会选择 softmax 回归还是多个 logistic 回归分类器呢？
在第一个例子中，三个类别是互斥的，因此更适于选择softmax回归分类器 。而在第二个例子中，建立三个独立的 logistic回归分类器更加合适。

在神经网络的最后一层，你将会像往常一样计算各层的线性部分，𝑧[𝑙]这是最后一层的𝑧变量，记住这是大写𝐿层，和往常一样，计算方法是𝑧[𝑙] = 𝑊[𝑙]𝑎[𝐿−1] + 𝑏[𝑙]，算出了𝑧之后，
你需要应用 Softmax 激活函数，这个激活函数对于 Softmax 层而言有些不同，它的作用是这样的。首先，我们要计算一个临时变量，我们把它叫做 t，它等于𝑒xp(𝑧[𝑙])，这适用于每个元素，
而这里的𝑧[𝑙]，在我们的例子中，𝑧[𝑙]是 4×1 的，四维向量𝑡 = 𝑒xp(𝑧[𝑙])，这是对所有元素求幂，𝑡也是一个 4×1 维向量，然后输出的𝑎[𝑙]，基本上就是向量𝑡，但是会归一化，使和为 1。因此
𝑎[𝑙] = 𝑒xp(𝑧[𝑙]) / ∑ ti (这一步就是累加所有的输出概率的指数函数)，换句话说，𝑎[𝑙]也是一个 4×1 维向量，而这个四维向量的第𝑖个元素，𝑎𝑖[𝑙] = 𝑡𝑖 / ∑ 𝑡𝑖 

简单来说，使用softmax相当于对最后产生的z值套上一个以e为底的指数函数然后在进行归一化，求出来的a[l]输出矩阵实际上就是每个位置对应的数除以整个矩阵的和，最后得到一个相同形状的矩阵，
而每个位置的概率就是最后预测的相关概率。

神经网络的输出𝑎[𝑙]，也就是𝑦^，是一个 4×1 维向量，这个 4×1 向量的元素就是我们算出来的这四个数字，所以这种算法通过向量𝑧[𝑙]计算出总和为 1 的四个概率。
即，softmax的优势在于，最后预测的概率和为1，因此不会影响概率分布的正确性。

总结一下从𝑧[𝑙]到𝑎[𝑙]的计算步骤，整个计算过程，从计算幂到得出临时变量𝑡，再归一化，我们可以将此概括为一个 Softmax 激活函数。设𝑎[𝑙] = 𝑔[𝑙](𝑧[𝑙])，这一激活函数
的与众不同之处在于，这个激活函数𝑔 需要输入一个 4×1 维向量，然后输出一个 4×1 维向量。之前，我们的激活函数都是接受单行数值输入，例如 Sigmoid 和 ReLu 激活函数，输入
一个实数，输出一个实数。Softmax 激活函数的特殊之处在于，因为需要将所有可能的输出归一化，就需要输入一个向量，最后输出一个向量。那么 Softmax 分类器还可以代表其它的什么东西么？
我来举几个例子，你有两个输入𝑥1，𝑥2，它们直接输入到 Softmax 层，它有三四个或者更多的输出节点，输出𝑦^，我将向你展示一个没有隐藏层的神经网络，它所做的就是计算𝑧[1] = 𝑊[1]𝑥 + 𝑏[1]，
而输出的出𝑎[𝑙]，或者说𝑦^，𝑎[𝑙] = 𝑦 = 𝑔(𝑧[1])，就是𝑧[1]的 Softmax 激活函数，这个没有隐藏层的神经网络应该能让你对 Softmax 函数能够代表的东西有所了解。

从作图上可以看出softmax函数在线性决策边界指定上的作用，对于多分类问题，应用softmax函数进行合理的边界划分，并且这些边界中的样本是不具有交叉关系的，因此对每一类的概率预测之和为1

3.9 训练一个 Softmax 分类器（Training a Softmax classifier）
softmax函数的求导过程参考：https://zhuanlan.zhihu.com/p/86787709

Softmax 这个名称的来源是与所谓 hardmax 对比，hardmax 会把向量𝑧变成这个向量[1 0 0 0]，hardmax 函数会观察𝑧的元素，然后在𝑧中最大元素的位置放上 1，其它位置放上 0，这是一个 hardmax，
也就是最大的元素的输出为 1，其它的输出都为 0。与之相反，Softmax 所做的从𝑧到这些概率的映射更为温和，我不知道这是不是一个好名字，但至少这就是 softmax这一名称背后所包含的想法，
与 hardmax 正好相反。（对于C = 2的softmax，实际上就可以称为一个logistic回归，即softmax实际上是对logistic回归的推广）

hardmax（类比于argmax）：
y = f(t) 是一般常见的函数式，如果给定一个t值，f（t）函数式会赋一个值给y。
y = max f(t) 代表：y 是f(t)函式所有的值中最大的output。
y = argmax f(t) 代表：y 是f(t)函式中，会产生最大output的那个参数t。
假设有一个函式 f(t)，t 的可能范围是 {0,1,2}，f(t=0) = 10 ; f(t=1) = 20 ; f(t=2) = 7，那分别对应的y如下：
y = max f(t) = 20
y= argmax f(t) = 1

简单的说：hardmax（类argmax）实际上是一个映射，将自变量x对应的最大值（最大概率）那一项进行赋值1，其他小概率项都赋值为0。(在argmax中体现为输出因变量最大值对应的自变量值)

接下来我们来看怎样训练带有 Softmax 输出层的神经网络，具体而言，我们先定义训练神经网络使会用到的损失函数。举个例子，我们来看看训练集中某个样本的目标输出，真实
标签是[0 1 0 0]，用上一个视频中讲到过的例子，这表示这是一张猫的图片，因为它属于类 1，现在我们假设你的神经网络输出的是𝑦^，𝑦^是一个包括总和为 1 的概率的向量，
𝑦 = [0.3 0.2 0.1 0.4]，你可以看到总和为 1，这就是𝑎[𝑙]，𝑎[𝑙] = 𝑦 = [0.3 0.2 0.1 0.4]。对于这个样本神经网络的表现不佳，这实际上是一只猫，但却只分配到 20%是猫的概率，
所以在本例中表现不佳。

那么你想用什么损失函数来训练这个神经网络？在 Softmax 分类中，我们一般用到的损失函数是𝐿(𝑦^ , 𝑦) = − ∑ yj 𝑙𝑜𝑔 𝑦^j  ，我们来看上面的单个样本来更好地理解整个过程。注意
在这个样本中𝑦1 = 𝑦3 = 𝑦4 = 0，因为这些都是 0，只有𝑦2 = 1，如果你看这个求和，所有含有值为 0 的𝑦𝑗的项都等于 0，最后只剩下−𝑦2 * 𝑙𝑜𝑔 𝑦^2，因为当你按照下标𝑗全部加起来，所有
的项都为0，除了𝑗 = 2时，又因为𝑦2 = 1，所以它就等于− 𝑙𝑜𝑔 𝑦^2 。𝐿(𝑦^ , 𝑦) = − ∑ 𝑦𝑗 * log 𝑦^𝑗  = −𝑦2 * 𝑙𝑜𝑔 𝑦^2 = − 𝑙𝑜𝑔 𝑦^2 这就意味着，如果你的学习算法试图将它变小，
因为梯度下降法是用来减少训练集的损失的，要使它变小的唯一方式就是使−log 𝑦^2变小，要想做到这一点，就需要使𝑦^2尽可能大，因为这些是概率，所以不可能比 1 大。

C = 4，表示一共有四个分类。如果有m个样本，最后产生的预测矩阵形状与Y（y以m个样本的形式堆叠成矩阵）的形状相同。因此，最后产生的矩阵形状为C * m

有 Softmax 输出层时如何实现梯度下降法，这个输出层会计算𝑧[𝑙]，它是𝐶 × 1维的，在这个例子中是 4×1，然后你用 Softmax 激活函数来得到𝑎[𝑙]或者说𝑦，
然后又能由此计算出损失。我们已经讲了如何实现神经网络前向传播的步骤，来得到这些输出，并计算损失，那么反向传播步骤或者梯度下降法又如何呢？其实初始化反向传播所需要
的关键步骤或者说关键方程是这个表达式𝑑𝑧[𝑙] = 𝑦^ − 𝑦，你可以用𝑦^这个 4×1 向量减去𝑦这个4×1 向量，你可以看到这些都会是 4×1 向量，当你有 4 个分类时，在一般情况下就是𝐶 × 1，
这符合我们对𝑑𝑧的一般定义，这是对𝑧[𝑙]损失函数的偏导数（𝑑𝑧[𝑙] = 𝜕𝐽 / 𝜕𝑧[𝑙]）

3.10 深度学习框架（Deep Learning frameworks）
框架的选择标准：
一个重要的标准就是便于编程，这既包括神经网络的开发和迭代，还包括为产品进行配置，为了成千上百万，甚至上亿用户的实际使用，取决于你想要做什么。
第二个重要的标准是运行速度，特别是训练大数据集时，一些框架能让你更高效地运行和训练神经网络。还有一个标准人们不常提到，但我觉得很重要，那就是这个框架是否真的开放，要是一
个框架真的开放，它不仅需要开源，而且需要良好的管理。

3.11 TensorFlow
使用TensorFlow进行简单的梯度下降（首先可以使用非向量化的过程来进行计算，注意TensorFlow中的运算符重载，重载帮助我们可以写出非函数嵌套形式的表达式）
在熟悉之后就可以使用向量化来加速，将参数进行向量化。

TensorFlow中的梯度下降：标准代码
import numpy as np
import tensorflow as tf

coefficients = np.array([[1],[-20],[25]]) # 这里的系数就是定义的损失函数的系数 损失函数：w² - 10w + 25

w = tf.Variable([0], dtype = tf.float32)
x = tf.placeholder(tf.float32, [3,1])
cost = x[0][0] * w ** 2 + x[1][0] * w + x[2][0] # 这里的数据对应上面的placeholder中的数组
train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)
init = tf.global_variables_initializer()

session = tf.Session()      # with tf.session() as session:
session.run(init)           #   session.run(init)
print(session.run(w))       #   print(session.run(w))

for i in range(1000):
  session.run(train, feed_dict = {x:coefficients})
print(session.run)

核心：计算损失函数，建立计算图；
编程框架可以自动完成反向传播的过程，不需要用户自己计算反向传播的求导过程，从而变得高效
































