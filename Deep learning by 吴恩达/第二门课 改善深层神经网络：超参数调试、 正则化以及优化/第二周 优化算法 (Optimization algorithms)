2.1 Mini-batch 梯度下降（Mini-batch gradient descent）
为什么要使用mini-batch分割数据集？数据集中的数据文件太多，如果一次性遍历完所有的数据效率太低，对数据集进行分隔可以有效地加快我们的训练效率。

batch 梯度下降法指的是我们之前讲过的梯度下降法算法，就是同时处理整个训练集，这个名字就是来源于能够同时看到整个 batch 训练集的样本被处理，这个名字不怎么样，但就是这样叫它。
相比之下，mini-batch 梯度下降法，每次同时处理的单个的 mini-batch 𝑋{𝑡}和𝑌{𝑡}，而不是同时处理全部的𝑋和𝑌训练集。

mini-batch:把训练集分割为小一点的子集训练，这些子集被取名为 mini-batch，假设每一个子集中只有 1000 个样本，那么把其中的𝑥(1)到𝑥(1000)取出来，将其称为第一个子训练集，也
叫做 mini-batch，然后你再取出接下来的 1000 个样本，从𝑥(1001)到𝑥(2000)，然后再取 1000个样本。
𝑋{𝑡}和𝑌{𝑡}的维数：如果𝑋{1}是一个有 1000 个样本的训练集，或者说是 1000 个样本的𝑥值，所以维数应该是(𝑛𝑥, 1000)，𝑋{2}的维数应该是(𝑛𝑥, 1000)，以此类推。因此所有的子集
维数都是(𝑛𝑥, 1000)，而这些（𝑌{𝑡}）的维数都是(1,1000)

mini-batch的数量𝑡组成了𝑋{𝑡}和𝑌{𝑡}，其中每个X{t}和Y{t}拥有相同的列数（因为对于每个子集来说，样本数都是不变的）
符号的定义 （i）表示第i个样本，[l]表示第l层的数据，{t}表示第t个mini-batch的数据

在训练集上运行 mini-batch 梯度下降法，你运行 for t=1……5000，因为我们有 5000 个各有 1000 个样本的组，在 for 循环里你要做得基本就是对𝑋{𝑡}和𝑌{𝑡}执行一步梯度下降法。
假设你有一个拥有1000个样本的训练集，而且假设你已经很熟悉一次性处理完的方法，你要用向量化去几乎同时处理 1000 个样本。
首先对输入也就是𝑋{𝑡}，执行前向传播，然后执行𝑧[1] = 𝑊[1]𝑋 + 𝑏[1]，之前我们这里只有，但是现在你正在处理整个训练集，你在处理第一个 mini-batch，在处理 mini-batch 时它
变成了𝑋{𝑡}，即𝑧[1] = 𝑊[1]𝑋{𝑡} + 𝑏[1]，然后执行𝐴[1]𝑘 = 𝑔[1](𝑍[1])，之所以用大写的𝑍是因为这是一个向量内涵，以此类推，直到𝐴[𝐿] = 𝑔[𝐿](𝑍[𝐿])，这就是你的预测值。注意这里你需要
用到一个向量化的执行命令，这个向量化的执行命令，一次性处理 1000 个而不是 500 万个样本。
使用 batch 梯度下降法，一次遍历训练集只能让你做一个梯度下降，使用 mini-batch 梯度下降法，一次遍历训练集，能让你做 5000 个梯度下降。

即，mini-batch的引入减少了每次运行处理的数据数，增加了处理的效率，其他的步骤都和梯度下降一样处理。 
此时计算成本函数的m样本量就发生变化，不再是全部的样本量了，因此参数m需要进行调整，同时正则化中的参数也需要进行修改。

epoch：对所有数据进行迭代一次
batch size：每次送入的数据样本数
iteration：完成一个epoch迭代的次数，相当于epoch / batch size

2.2 理解 mini-batch 梯度下降法（Understanding mini-batch gradient descent）
使用batch梯度下降法的明显特点是，每代的迭代都会使成本函数下降，如果没有发现下降反而上升，可能就是学习率设置的比较高，导致没有获取到最优的成本函数。
使用mini-batch梯度下降法，可能不会每次迭代都会使成本函数得到优化，这是因为每次送进去的样本都相当于一个全新的训练集，部分训练集可能比较容易计算，而某些训练集会比较难以计算，
这种不确定性导致mini-batch不能每次都产生成本函数的下降，但是总的趋势应该是下降的。

mini-batch大小的设定：
如果设置成1，就相当于随机梯度下降法（SGD stichastic gradient descent）sgd需要最多次数的迭代，而且其效率不高。
如果设置成整个训练集大小m，就相当于batch随机梯度下降，每次送进去的数据就是整个训练集，这样的缺点是数据量太大，运行的效率太低。

sgd永远不会收敛，会在最小值的附近进行波动，产生的噪声也比较多，某一个样本的错误可能会使sgd偏离正确的方向。通过减小学习率可以改善噪声比较大的问题，但是缺少了向量化的加速，效率比较低。
batch梯度下降的下降幅度比较大，噪声低，可以不断地寻找最小值。缺点是运行的时间太长，一次迭代的速率太慢。

所以实践中最好选择不大不小的 mini-batch 尺寸，实际上学习率达到最快。你会发现两个好处，一方面，你得到了大量向量化，上个视频中我们用过的例子中，如果 mini-batch 大小为
1000 个样本，你就可以对 1000 个样本向量化，比你一次性处理多个样本快得多。另一方面，你不需要等待整个训练集被处理完就可以开始进行后续工作，再用一下上个视频的数字，每
次训练集允许我们采取 5000 个梯度下降步骤，所以实际上一些位于中间的 mini-batch 大小效果最好。

用 mini-batch 梯度下降法，我们从这里开始，一次迭代这样做，两次，三次，四次，它不会总朝向最小值靠近，但它比随机梯度下降要更持续地靠近最小值的方向，它也不一定在
很小的范围内收敛或者波动，如果出现这个问题，可以慢慢减少学习率。

首先，如果训练集较小，直接使用 batch 梯度下降法，样本集较小就没必要使用 mini-batch 梯度下降法，你可以快速处理整个训练集，所以使用 batch 梯度下降法也很好，这里
的少是说小于 2000 个样本，这样比较适合使用 batch 梯度下降法。不然，样本数目较大的话，一般的 mini-batch 大小为 64 到 512，考虑到电脑内存设置和使用的方式，
如果 mini-batch 大小是 2 的𝑛次方，代码会运行地快一些，64 就是 2 的 6 次方，以此类推，128 是 2 的 7 次方，256 是 2 的 8 次方，512 是 2 的 9 次方。
所以我经常把 mini-batch 大小设成 2 的次方。在上一个视频里，我的 mini-batch 大小设为了 1000，建议你可以试一下 1024，也就是2 的 10 次方。
也有 mini-batch 的大小为 1024，不过比较少见，64 到 512 的 mini-batch 比较常见。

最后需要注意的是在你的 mini-batch 中，要确保𝑋{𝑡}和𝑌{𝑡}要符合 CPU/GPU 内存，取决于你的应用方向以及训练集的大小。如果你处理的 mini-batch 和 CPU/GPU 内存不相符，不
管你用什么方法处理数据，你会注意到算法的表现急转直下变得惨不忍睹，所以我希望你对一般人们使用的 mini-batch 大小有一个直观了解。事实上 mini-batch 大小是另一个重要的变
量，你需要做一个快速尝试，才能找到能够最有效地减少成本函数的那个，我一般会尝试几个不同的值，几个不同的 2 次方，然后看能否找到一个让梯度下降优化算法最高效的大小。
希望这些能够指导你如何开始找到这一数值。

2.3 指数加权平均数（Exponentially weighted averages）
程序中的移动平均值 𝑣𝑡 = 𝛽 𝑣t-1 + (1 − 𝛽)𝜃𝑡  即 温度的局部平均值（移动平均值） = 前一天温度的β倍 + 当日温度的（1 - β）倍
假设这里的β是0.9，即前一天的温度的移动平均值的占比为0.9，当日的温度占当日温度移动平均值的0.1。此时可以视当日温度的移动平均值为10天的平均温度，vt相当于1 / (1 - β)的每日温度
如果β的取值是0.98，那么就相当于50天温度的平均值。
这里的理解：展开vt-1我们可以得到前一天温度的1-β倍加上大前天温度的移动平均值，由于β是一个比较接近于1的数，因此，之前的每日温度的1-β倍都被比较好的保留了下来，最后的某天温度的移动平均值
就变成了一个等比数列性质的每日温度的1-β倍的和，如果忽略这个等比数列的公比（因为接近于1），我们可以得到每天温度所占的比例为1/(1-β)，相当于1/(1-β)天的每日温度的平均值。

这个高值𝛽要注意几点，你得到的曲线要平坦一些，原因在于你多平均了几天的温度，所以这个曲线，波动更小，更加平坦，缺点是曲线进一步右移，因为现在平均的温度值更多，
要平均更多的值，指数加权平均公式在温度变化时，适应地更缓慢一些，所以会出现一定延迟，因为当𝛽 = 0.98，相当于给前一天的值加了太多权重，只有 0.02 的权重给了当日的值，
所以温度变化时，温度上下起伏，当𝛽 较大时，指数加权平均值适应地更缓慢一些。

因此，适当的选择β的值是选用指数加权平均数时需要重点考虑的问题，要权衡低数值β高噪声高反应灵敏度与高数值β低噪声地反应灵敏度。

2.4 理解指数加权平均数（ Understanding exponentially weighted averages）
指数加权平均数的基本公式：  𝑣𝑡 = 𝛽𝑣𝑡−1 + (1 − 𝛽)𝜃𝑡
展开形式： 𝑣100 = 0.1 𝜃100 + 0.1 × 0.9 𝜃99 + 0.1 × (0.9)² 𝜃98 + 0.1 × (0.9)三次方 𝜃97 + 0.1 × (0.9)四次方 𝜃96 + ⋯

过所有的这些系数（0.10.1 × 0.90.1 × (0.9)2 0.1 × (0.9)3 …），相加起来为 1 或者逼近 1，我们称之为偏差修正

到底需要平均多少天的温度?
实际上(0.9)的10次方大约为 0.35，这大约是1/𝑒， e 是自然算法的基础之一。大体上说，如果有1 − 𝜀，在这个例子中，𝜀 = 0.1，所以1 − 𝜀 = 0.9，(1 − 𝜀)的(1/𝜀)次方约等于1/𝑒，
大约是 0.34，0.35，换句话说，10 天后，曲线的高度下降到1/3，相当于在峰值的1 /𝑒。

这里用到了重要极限 (1 + n)的1/n次方 ≈ 1/e （变形） 因此当β取值为0.98的时候 需要平均50天的数据才能达到1/e的水平

现在解释一下算法，可以将𝑣0，𝑣1，𝑣2等等写成明确的变量，不过在实际中执行的话，你要做的是，一开始将𝑣初始化为 0，然后在第一天使𝑣: = 𝛽𝑣 + (1 − 𝛽)𝜃1，然后第二天，更
新𝑣值，𝑣: = 𝛽𝑣 + (1 − 𝛽)𝜃2，以此类推，有些人会把𝑣加下标，来表示𝑣是用来计算数据的指数加权平均数。
𝑣𝜃 = 0，然后每一天，拿到第𝑡天的数据，把𝑣更新为𝑣: = 𝛽 𝑣 sub(𝜃) + (1 − 𝛽)𝜃t

指数加权平均数公式的好处之一在于，它占用极少内存，电脑内存中只占用一行数字而已，然后把最新数据代入公式，不断覆盖就可以了，正因为这个原因，其效率，它基本上只
占用一行代码，计算指数加权平均数也只占用单行数字的存储和内存，当然它并不是最好的，也不是最精准的计算平均数的方法。如果你要计算移动窗，你直接算出过去 10 天的总和，
过去 50 天的总和，除以 10 和 50 就好，如此往往会得到更好的估测。但缺点是，如果保存所有最近的温度数据，和过去 10 天的总和，必须占用更多的内存，执行更加复杂，计算成
本也更加高昂。

2.5 指数加权平均的偏差修正 （Bias correction in exponentially weighted averages）
计算移动平均数的时候，初始化𝑣0 = 0，𝑣1 = 0.98𝑣0 + 0.02𝜃1，但是𝑣0 = 0，所以这部分没有了（0.98𝑣0），所以𝑣1 = 0.02𝜃1，所以如果一天温度是 40 华氏度，
那么𝑣1 = 0.02𝜃1 = 0.02 × 40 = 8，因此得到的值会小很多，所以第一天温度的估测不准。
𝑣2 = 0.98 𝑣1 + 0.02 𝜃2，如果代入𝑣1，然后相乘，所以𝑣2 = 0.98 × 0.02𝜃1 + 0.02𝜃2 = 0.0196𝜃1 + 0.02𝜃2，假设𝜃1和𝜃2都是正数，计算后𝑣2要远小于𝜃1和𝜃2，所以𝑣2不能很好估测
出这一年前两天的温度。

有个办法可以修改这一估测，让估测变得更好，更准确，特别是在估测初期，也就是不用𝑣𝑡，而是用 𝑣𝑡/1−𝛽的𝑡次方，t 就是现在的天数。举个具体例子，当𝑡 = 2时，1 − 𝛽的𝑡次方 = 1 − 0.982 = 0.0396，
因此对第二天温度的估测变成了 𝑣2 / 0.0396 = 0.0196𝜃1+0.02𝜃2 / 0.0396 ，也就是𝜃1和𝜃2的加权平均数，并去除了偏差。你会发现随着𝑡增加，𝛽𝑡接近于 0，所以当𝑡很大的时候，偏差修正几乎没有作用，
因此当𝑡较大的时候，紫线基本和绿线重合了。不过在开始学习阶段，你才开始预测热身练习，偏差修正可以帮助你更好预测温度，偏差修正可以帮助你使结果从紫线变成绿线。

2.6 动量梯度下降法（Gradient descent with Momentum）
还有一种算法叫做 Momentum，或者叫做动量梯度下降法，运行速度几乎总是快于标准的梯度下降算法
动量梯度下降法用来解决sgd，batch，mini-batch下降法的弊端，这些方法纵轴的摆动比较大,容易偏离函数的取值范围（需要使用较小的学习率）。
因此，动量梯度下降法可以降低纵轴方向的均值，同时横轴方向运动更快.

方法： 𝑣 sub（𝑑𝑊） = 𝛽 * 𝑣 sub（𝑑𝑊） +(1 − 𝛽)𝑑𝑊，这跟我们之前的计算相似，也就是𝑣 = 𝛽𝑣 + (1 − 𝛽)𝜃sub(𝑡)，𝑑𝑊的移动平均数，接着同样地计算𝑣 sub（𝑑𝑏），
𝑣 sub（𝑑𝑏） = 𝛽*𝑣 sub(𝑑𝑏) + (1 − 𝛽)𝑑𝑏，然后重新赋值权重，𝑊: = 𝑊 − 𝑎*𝑣sub(𝑑𝑊)，同样𝑏: = 𝑏 − 𝑎*𝑣sub(𝑑𝑏)，这样就可以减缓梯度下降的幅度。

有两个超参数，学习率𝑎以及参数𝛽，𝛽控制着指数加权平均数。𝛽最常用的值是0.9，我们之前平均了过去十天的温度，所以现在平均了前十次迭代的梯度。实际上𝛽为 0.9
时，效果不错，你可以尝试不同的值，可以做一些超参数的研究，不过 0.9 是很棒的鲁棒数。那么关于偏差修正，所以你要拿𝑣 sub(𝑑𝑊)和𝑣 sub(𝑑𝑏)除以1 − 𝛽的𝑡次方，实际上人们不这么做，
因为 10 次迭代之后，因为你的移动平均已经过了初始阶段。实际中，在使用梯度下降法或动量梯度下降法时，人们不会受到偏差修正的困扰。当然𝑣 sub(𝑑𝑊)初始值是 0，要注意到这是和𝑑𝑊拥有相同维
数的零矩阵，也就是跟𝑊拥有相同的维数，𝑣 sub(𝑑𝑏)的初始值也是向量零，所以和𝑑𝑏拥有相同的维数，也就是和𝑏是同一维数.

最后要说一点，如果你查阅了动量梯度下降法相关资料，你经常会看到一个被删除了的专业词汇，1 − 𝛽被删除了，最后得到的是𝑣 sub(𝑑𝑊) = 𝛽*𝑣 sub(𝑑𝑊) + 𝑑𝑊。用紫色版本的结果就是，所
以𝑣 sub(𝑑𝑊)缩小了1 − 𝛽倍，相当于乘以 1 / 1−𝛽，所以你要用梯度下降最新值的话，𝑎要根据 1 / 1−𝛽相应调整。

总结一下，如果使用除以1-β以后的参数作为梯度的下降值，那么就可能需要在修改β后同样修改学习率。如果不这样做也是完全可以的，β的常用值是0.9

2.7 RMSprop
RMSprop 的算法，全称是 root mean square prop 算法，它也可以加速梯度下降
使用RMSprop算法的目的：减缓𝑏方向的学习，即纵轴方向，同时加快，至少不是减缓横轴方向的学习

在第𝑡次迭代中，该算法会照常计算当下mini-batch的微分𝑑𝑊，𝑑𝑏，所以我会保留这个指数加权平均数，我们用到新符号𝑆 sub(𝑑𝑊)，而不是𝑣 sub(𝑑𝑊)，因此𝑆 sub(𝑑𝑊) = 𝛽*𝑆 sub(𝑑𝑊) + (1 − 𝛽)(𝑑𝑊)²
，澄清一下，这个平方的操作是针对这一整个符号的，这样做能够保留微分平方的加权平均数，同样𝑆 sub(𝑑𝑏) = 𝛽*𝑆 sub(db) + (1 − 𝛽)(𝑑𝑏)²

接着 RMSprop 会这样更新参数值，𝑊: = 𝑊 − 𝑎 * 𝑑𝑊/(根号下𝑆 sub(𝑑𝑊))，𝑏: = 𝑏 − 𝛼 * 𝑑𝑏 / (根号下𝑆 sub(db))

理解：这里的梯度迭代可以很好地控制纵轴的变化，db如果是一个比较大的值（db原来带来了比较大的纵轴波动），那么在更新参数的过程中db就会变得比较小，因为分母的根号下S sub(db)比较大。
但是这里我们的S sub(dW)可能是一个比较小的值，或许会导致横轴的学习速率变慢，因此我们可以加大学习率a来增加学习速度而不会产生负面的影响（比如纵轴的波动）

问题：当涉及到除法的时候就需要很慎重，因为除数可能是一个很小的数，这样可能会导致梯度爆炸。因此一般需要在分母上加上一个很小的ε，通常是10的-8次方，从而保证得到的W不会太小

RMSprop，全称是均方根，因为你将微分进行平方，然后最后使用平方根。

2.8 Adam 优化算法(Adam optimization algorithm)
大多数优化算法只对某种特殊的网络结构是有效的，这里的RMSprop和Adam是优秀的可以适用于多种网络模型的优化算法。Adam 优化算法基本上就是将 Momentum 和 RMSprop 结合在一起。

使用 Adam 算法：
1.初始化：
𝑣 sub(𝑑𝑊) = 0，𝑆 sub(𝑑𝑊) = 0，𝑣 sub(𝑑𝑏) = 0，𝑆 sub(𝑑𝑏) = 0，在第𝑡次迭代中，你要计算微分，用当前的 mini-batch 计算𝑑𝑊，𝑑𝑏，一般你会用 mini-batch 梯度下降法。
接下来计算 Momentum 指数加权平均数，所以𝑣 sub(𝑑𝑊) = 𝛽1 * 𝑣 sub(𝑑𝑊) + (1 − 𝛽1)𝑑𝑊（使用𝛽1，这样就不会跟超参数𝛽2混淆，因为后面 RMSprop 要用到𝛽2），
使用 Momentum 时我们肯定会用这个公式，但现在不叫它𝛽，而叫它𝛽1。同样𝑣 sub(𝑑𝑏) = 𝛽1*𝑣 sub(𝑑𝑏) + (1 − 𝛽1)𝑑𝑏。

2.接着使用RMSprop更新参数：
𝑆 sub(𝑑𝑊) = 𝛽*𝑆 sub(𝑑𝑊) + (1 − 𝛽)(𝑑𝑊)²
𝑆 sub(𝑑𝑏) = 𝛽*𝑆 sub(db) + (1 − 𝛽)(𝑑𝑏)²
（相当于 Momentum 更新了超参数𝛽1，RMSprop 更新了超参数𝛽2）

3.偏差修正：
计算偏差修正，𝑣 sup(corrected) sub(𝑑𝑊)  𝑣 sup(corrected) sub(𝑑b)
𝑣 sup(corrected) sub(𝑑𝑊)  = 𝑣 sub(𝑑𝑊) / 1 - 𝛽1的t次方
𝑣 sup(corrected) sub(𝑑b)  = 𝑣 sub(𝑑b) / 1 - 𝛽1的t次方

𝑆也使用偏差修正，S sup(corrected) sub(𝑑𝑊)  S sup(corrected) sub(𝑑b)
S sup(corrected) sub(𝑑𝑊) = S sub(𝑑𝑊) / 1 - 𝛽2的t次方 
S sup(corrected) sub(𝑑b) = S sub(𝑑b) / 1 - 𝛽2的t次方 

4.更新权重：
更新权重，W sup(corrected) sub(𝑑𝑊) 
W = W - a * 𝑣 sup(corrected) sub(𝑑𝑊) / {根号下[S sup(corrected) sub(𝑑𝑊)] + ε}
b = b - a * 𝑣 sup(corrected) sub(𝑑b) / {根号下[S sup(corrected) sub(𝑑b)] + ε}
ε 是一个很小的数，通常可以定义为10的-8次方
TIP：如果你只是用 Momentum，使用𝑣 sub(𝑑𝑊)或者修正后的𝑣 sub(𝑑𝑊)，但现在我们加入了 RMSprop 的部分，所以我们要除以修正后𝑆 sub(𝑑𝑊)的平方根加上𝜀）。

本算法中有很多超参数，超参数学习率𝑎很重要，也经常需要调试，你可以尝试一系列值，然后看哪个有效。𝛽1常用的缺省值为 0.9，这是 dW 的移动平均数，也就是𝑑𝑊的加权平
均数，这是 Momentum 涉及的项。至于超参数𝛽2，Adam 论文作者，也就是 Adam 算法的发明者，推荐使用 0.999，这是在计算(𝑑𝑊)2以及(𝑑𝑏)2的移动加权平均值，关于𝜀的选择其实
没那么重要，Adam 论文的作者建议𝜀为10的−8，但你并不需要设置它，因为它并不会影响算法表现。但是在使用 Adam 的时候，人们往往使用缺省值即可，𝛽1，𝛽2和𝜀都是如此，我觉
得没人会去调整𝜀，然后尝试不同的𝑎值，看看哪个效果最好。你也可以调整𝛽1和𝛽2，但我认识的业内人士很少这么干。

Adam 代表的是 Adaptive Moment Estimation，𝛽1用于计算，这个微分（𝑑𝑊），叫做第一矩，𝛽2用来计算平方数的指数加权平均数（(𝑑𝑊)²），叫做第二矩，
所以 Adam 的名字由此而来，但是大家都简称 Adam 权威算法。

2.9 学习率衰减(Learning rate decay)
假设你要使用 mini-batch 梯度下降法，mini-batch 数量不大，大概 64 或者 128 个样本，在迭代过程中会有噪音（蓝色线），下降朝向这里的最小值，但是不会精确地收敛，所以你
的算法最后在附近摆动，并不会真正收敛，因为你用的𝑎是固定值，不同的 mini-batch 中有噪音。

但要慢慢减少学习率𝑎的话，在初期的时候，𝑎学习率还较大，你的学习还是相对较快，但随着𝑎变小，你的步伐也会变慢变小，所以最后你的曲线（绿色线）会在最小值附近的一
小块区域里摆动，而不是在训练过程中，大幅度在最小值附近摆动。

所以慢慢减少𝑎的本质在于，在学习初期，你能承受较大的步伐，但当开始收敛的时候，小一些的学习率能让你步伐小一些。

你应该拆分成不同的 mini-batch，第一次遍历训练集叫做第一代。第二次就是第二代，依此类推，你可以将𝑎学习率设为𝑎 = a0 * 1 / (1 + 𝑑𝑒𝑐𝑎𝑦𝑟𝑎𝑡𝑒 * epoch-num) 
（decay-rate称为衰减率，epoch-num 为代数，𝛼0为初始学习率），注意这个衰减率是另一个你需要调整的超参数。

除了这个学习率衰减的公式，还会用其它的公式：
指数衰减：其中𝑎相当于一个小于 1 的值，如𝑎 = 0.95epoch−num𝑎0，所以你的学习率呈指数下降。
𝑎 = 𝑘 / 根号下epoch−num * 𝑎0 
𝑎 = 𝑘 / 根号下𝑡 * 𝑎0 (t为1 epoch遍历的mini-batch数)   
离散下降的学习率，也就是某个步骤有某个学习率，一会之后，学习率减少了一半，一会儿减少一半，一会儿又一半，这就是离散下降（discrete stair cease）

2.10 局部最优的问题(The problem of local optima)
在梯度进行下降的过程中，多元函数可能会产生多个局部最优点，这些点称为鞍点（在微分方程中，沿着某一方向是稳定的，另一条方向是不稳定的奇点）
（1）鞍点可能是局部的极小点或者极大点，这些极值点不一定是我们最终需要找寻的全局最优点（或者近似的全局最优点）。在高维空间（多个参数W）的情况下，鞍点更加普遍，因此需要考虑梯度下降的
停止条件。
（2）同时，在梯度迭代中，迭代的梯度可能会遇到代价函数中的平稳段，这需要很长时间的缓慢迭代，因此这是Momentum 或是RMSprop，Adam 这样的算法，能够加速学习算法的地方。
更成熟的优化算法，如 Adam 算法，能够加快速度，让你尽早往下走出平稳段

但是在高维空间中，不一定会困在极差的局部最优点处，条件是网络的参数十分多，成本函数也是一个高维的函数。































